import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
from pathlib import Path
import os
from PIL import Image
import torchvision.transforms as T
from tqdm import tqdm
import logging
import sys
from sklearn.model_selection import train_test_split
import torch.optim as optim
from concurrent.futures import ThreadPoolExecutor
import time
import gc
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from mpl_toolkits.mplot3d import Axes3D
from sklearn.metrics import fbeta_score
import warnings # to suppress FutureWarning cuda warnings 

# Set random seed for reproducibility
torch.manual_seed(42)
np.random.seed(42)

# Configure logging
logger = logging.getLogger('')
logger.setLevel(logging.INFO)
logger.handlers = []
file_handler = logging.FileHandler("/kaggle/working/training.log", mode='w')
file_handler.setLevel(logging.INFO)
file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
file_handler.flush = lambda: file_handler.stream.flush()  # Force flush
logger.addHandler(file_handler)
console_handler = logging.StreamHandler(sys.stdout)
console_handler.setLevel(logging.ERROR)
console_handler.setFormatter(logging.Formatter('%(levelname)s - %(message)s'))
logger.addHandler(console_handler)
logger.info("Logging initialized to /kaggle/working/training.log")


# Redirect print to logger
def redirect_print_to_log(*args, **kwargs):
    logger.info(" ".join(map(str, args)))
sys.stdout.write = redirect_print_to_log

# MultiHeadSelfAttention
class MultiHeadSelfAttention(nn.Module):
    def __init__(self, in_channels, num_heads=8):
        super(MultiHeadSelfAttention, self).__init__()
        assert in_channels % num_heads == 0, "in_channels must be divisible by num_heads"
        self.in_channels = in_channels
        self.num_heads = num_heads
        self.head_dim = in_channels // num_heads
        self.query = nn.Conv2d(in_channels, in_channels, kernel_size=1)
        self.key = nn.Conv2d(in_channels, in_channels, kernel_size=1)
        self.value = nn.Conv2d(in_channels, in_channels, kernel_size=1)
        self.out_proj = nn.Conv2d(in_channels, in_channels, kernel_size=1)
        self.gamma = nn.Parameter(torch.zeros(1))
        self.softmax = nn.Softmax(dim=-1)

    def forward(self, x):
        batch, channels, height, width = x.size()
        n_pixels = height * width
        proj_query = self.query(x).view(batch, self.num_heads, self.head_dim, n_pixels).permute(0, 1, 3, 2)
        proj_key = self.key(x).view(batch, self.num_heads, self.head_dim, n_pixels)
        proj_value = self.value(x).view(batch, self.num_heads, self.head_dim, n_pixels).permute(0, 1, 3, 2)
        energy = torch.matmul(proj_query, proj_key) / (self.head_dim ** 0.5)
        energy = torch.clamp(energy, min=-10, max=10)
        attention = self.softmax(energy)
        out = torch.matmul(attention, proj_value)
        out = out.permute(0, 1, 3, 2).contiguous().view(batch, self.in_channels, height, width)
        out = self.out_proj(out)
        return self.gamma * out + x

# EnhancedCABM2D
class EnhancedCABM2D(nn.Module):
    def __init__(self, in_channels, reduction=16):
        super(EnhancedCABM2D, self).__init__()
        self.global_pool = nn.AdaptiveAvgPool2d(1)
        self.fc1 = nn.Conv2d(in_channels, in_channels // reduction, kernel_size=1)
        self.fc2 = nn.Conv2d(in_channels // reduction, in_channels, kernel_size=1)
        self.sigmoid = nn.Sigmoid()
        self.conv_spatial1 = nn.Conv2d(in_channels, 1, kernel_size=7, padding=3, dilation=1, bias=False)
        self.conv_spatial2 = nn.Conv2d(in_channels, 1, kernel_size=7, padding=9, dilation=3, bias=False)
        self.conv_refine = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)
        self.bn = nn.BatchNorm2d(in_channels)
        self.relu = nn.ReLU(inplace=True)
        self.self_attention = MultiHeadSelfAttention(in_channels, num_heads=8)

    def forward(self, x):
        channel_avg = self.global_pool(x)
        channel_att = self.fc1(channel_avg)
        channel_att = self.relu(channel_att)
        channel_att = self.fc2(channel_att)
        channel_att = self.sigmoid(channel_att)
        x_channel = x * channel_att
        spatial_att1 = self.conv_spatial1(x_channel)
        spatial_att2 = self.conv_spatial2(x_channel)
        spatial_att = self.sigmoid(spatial_att1 + spatial_att2)
        x_spatial = x_channel * spatial_att
        x_self_att = self.self_attention(x_spatial)
        x_refined = self.conv_refine(x_self_att)
        x_refined = self.bn(x_refined)
        x_refined = self.relu(x_refined)
        return x + x_refined

# OptimizedCenterNet2D
class OptimizedCenterNet2D(nn.Module):
    def __init__(self, in_channels=1, out_channels=1):
        super(OptimizedCenterNet2D, self).__init__()
        self.enc1 = nn.Sequential(
            nn.Conv2d(in_channels, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.Dropout(0.3)
        )
        self.enc2 = nn.Sequential(
            nn.Conv2d(32, 64, kernel_size=3, padding=1, stride=2),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.Dropout(0.3)
        )
        self.enc3 = nn.Sequential(
            nn.Conv2d(64, 128, kernel_size=3, padding=1, stride=2),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.Dropout(0.3)
        )
        self.enc4 = nn.Sequential(
            nn.Conv2d(128, 256, kernel_size=3, padding=1, stride=2),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.Dropout(0.3)
        )
        self.attention = EnhancedCABM2D(in_channels=256)
        self.dec4 = nn.Sequential(
            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU()
        )
        self.dec3 = nn.Sequential(
            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU()
        )
        self.dec2 = nn.Sequential(
            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU()
        )
        self.heatmap_head = nn.Sequential(
            nn.Conv2d(32, out_channels, kernel_size=1),
            nn.Sigmoid()
        )
        self.size_head = nn.Conv2d(32, 2, kernel_size=1)
        self.offset_head = nn.Conv2d(32, 2, kernel_size=1)

    def forward(self, x):
        e1 = self.enc1(x)
        e2 = self.enc2(e1)
        e3 = self.enc3(e2)
        e4 = self.enc4(e3)
        e4_att = self.attention(e4)
        d4 = self.dec4(e4_att) + e3
        d3 = self.dec3(d4) + e2
        d2 = self.dec2(d3) + e1
        heatmap = self.heatmap_head(d2)
        size = self.size_head(d2)
        offset = self.offset_head(d2)
        return heatmap, size, offset

# CenterNetLoss
class CenterNetLoss(nn.Module):
    def __init__(self, gamma=2.0, size_weight=0.5, offset_weight=0.1):
        super(CenterNetLoss, self).__init__()
        self.gamma = gamma
        self.size_weight = size_weight
        self.offset_weight = offset_weight

    def gaussian_focal_loss(self, pred_heatmap, target_heatmap):
        pos_loss = -target_heatmap * (1 - pred_heatmap) ** self.gamma * torch.log(pred_heatmap + 1e-6)
        neg_loss = -(1 - target_heatmap) * pred_heatmap ** self.gamma * torch.log(1 - pred_heatmap + 1e-6)
        loss = (pos_loss + neg_loss).sum() / pred_heatmap.size(0)
        return loss

    def forward(self, pred_heatmap, pred_size, pred_offset, target_heatmap, target_size, target_offset):
        gfl = self.gaussian_focal_loss(pred_heatmap, target_heatmap)
        batch_size = pred_heatmap.size(0)
        pred_size_at_centers = torch.zeros(batch_size, 2, device=pred_heatmap.device)
        pred_offset_at_centers = torch.zeros(batch_size, 2, device=pred_heatmap.device)
        for i in range(batch_size):
            heatmap = pred_heatmap[i].squeeze()
            peak_idx = heatmap.view(-1).argmax()
            y = peak_idx // 256
            x = peak_idx % 256
            pred_size_at_centers[i] = pred_size[i, :, y, x]
            pred_offset_at_centers[i] = pred_offset[i, :, y, x]
        size_loss = F.mse_loss(pred_size_at_centers, target_size, reduction='mean') * self.size_weight
        offset_loss = F.mse_loss(pred_offset_at_centers, target_offset, reduction='mean') * self.offset_weight
        return gfl + size_loss + offset_loss


# FlagellarDataset - storage containing image tensors, heatmaps, sizes, offfsets and metadata
class FlagellarDataset(Dataset):
    def __init__(self, tomo_ids, csv_file=None, root_dir=None, new_size=(256, 256), trust_region=4, is_test=False):
        self.tomo_ids = tomo_ids
        self.csv_file = csv_file
        self.root_dir = Path(root_dir)
        self.new_size = new_size
        self.trust_region = trust_region
        self.is_test = is_test
        self.data = []
        self.spatial_augment = T.Compose([
            T.RandomHorizontalFlip(p=0.5),
            T.RandomRotation(degrees=10),
            T.RandomAffine(degrees=0, scale=(0.95, 1.05))
        ])
        self.image_augment = T.Compose([
            T.RandomApply([T.ColorJitter(brightness=0.1, contrast=0.1)], p=0.2)
        ])
        logger.info(f"Initializing {'test' if is_test else 'train/val'} dataset with {len(tomo_ids)} tomograms, is_test={is_test}")

        if csv_file and os.path.exists(csv_file) and not is_test:
            labels = pd.read_csv(csv_file)
            self.motors_map = labels.groupby('tomo_id').apply(
                lambda g: np.array(g[['Motor axis 0', 'Motor axis 1', 'Motor axis 2']].values[0], dtype=np.float32),
                include_groups=False
            ).to_dict()
            self.size_map = labels.groupby('tomo_id').agg({
                'Array shape (axis 1)': 'first',
                'Array shape (axis 2)': 'first',
                'Array shape (axis 0)': 'first',
                'Voxel spacing': 'first'
            }).to_dict('index')
            logger.info(f"Loaded labels for {len(self.motors_map)} tomograms from {csv_file}")

            skipped_tomograms = []
            for tomo_id in tqdm(self.tomo_ids, desc="Loading training data"):
                if tomo_id not in self.motors_map:
                    logger.warning(f"Tomogram {tomo_id} not in labels, skipping. Available tomo_ids: {sorted(list(self.motors_map.keys()))[:10]}...")
                    skipped_tomograms.append(tomo_id)
                    continue
                
                tomo_dir = self.root_dir.joinpath(tomo_id)
                if not tomo_dir.exists():
                    logger.warning(f"Tomogram {tomo_id} directory {tomo_dir} does not exist, skipping")
                    skipped_tomograms.append(tomo_id)
                    continue

                motor = self.motors_map[tomo_id]
                files = sorted(tomo_dir.glob('*.jpg'))
                num_slices = len(files)
                if num_slices == 0:
                    logger.warning(f"Tomogram {tomo_id} has no slices in {tomo_dir}, skipping")
                    skipped_tomograms.append(tomo_id)
                    continue

                if np.all(motor == -1):
                    center_z = num_slices // 2
                    z_start = max(0, center_z - self.trust_region)
                    z_end = min(num_slices, center_z + self.trust_region + 1)
                    slices_added = 0
                
                    for z in range(z_start, z_end):
                        slice_path = files[z] if z < len(files) else None
                        if not slice_path or not slice_path.exists():
                            logger.debug(f"Tomogram {tomo_id}, slice {z} not found at {slice_path or tomo_dir}, skipping slice")
                            continue
                
                        img = Image.open(slice_path).convert('L')
                        img = T.functional.resize(img, self.new_size)
                        img = T.functional.to_tensor(img)
                        img = (img - img.mean()) / (img.std() + 1e-8)
                
                        motor_norm = torch.tensor([-1, -1], dtype=torch.float32)
                        heatmap = torch.zeros(self.new_size)
                        size_target = torch.zeros(2, dtype=torch.float32)
                        offset_target = torch.zeros(2, dtype=torch.float32)
                
                        if not self.is_test:
                            img_aug = self.image_augment(img)
                            stacked = torch.stack([img_aug[0], heatmap], dim=0)
                            stacked_aug = self.spatial_augment(stacked)
                            img = stacked_aug[0].unsqueeze(0)
                            heatmap = stacked_aug[1]
                
                        self.data.append({
                            'tomo_id': tomo_id,
                            'slice': img,
                            'heatmap': heatmap,
                            'size': size_target,
                            'offset': offset_target,
                            'center': motor_norm,
                            'z': z,
                            'orig_shape': torch.tensor([self.size_map[tomo_id]['Array shape (axis 1)'],
                                                      self.size_map[tomo_id]['Array shape (axis 2)'],
                                                      num_slices], dtype=torch.float32),
                            'voxel_spacing': self.size_map[tomo_id]['Voxel spacing'],
                            'motor': torch.tensor(motor, dtype=torch.float32)
                        })
                        slices_added += 1
                
                    if slices_added == 0:
                        logger.warning(f"Tomogram {tomo_id} has no valid slices in trust region (z={z_start} to {z_end-1}), skipping")
                        skipped_tomograms.append(tomo_id)
                    else:
                        logger.debug(f"Processed tomogram {tomo_id}: Added {slices_added} slices (z={z_start} to {z_end-1})")
                    continue

                center_z = int(motor[0])
                z_start = max(0, center_z - self.trust_region)
                z_end = min(num_slices, center_z + self.trust_region + 1)
                slices_added = 0

                for z in range(z_start, z_end):
                    slice_path = files[z] if z < len(files) else None
                    if not slice_path or not slice_path.exists():
                        logger.debug(f"Tomogram {tomo_id}, slice {z} not found at {slice_path or tomo_dir}, skipping slice")
                        continue

                    img = Image.open(slice_path).convert('L')
                    img = T.functional.resize(img, new_size)
                    img = T.functional.to_tensor(img)
                    img = (img - img.mean()) / (img.std() + 1e-8)

                    motor_norm = torch.tensor([
                        motor[1] / self.size_map[tomo_id]['Array shape (axis 1)'],
                        motor[2] / self.size_map[tomo_id]['Array shape (axis 2)']
                    ], dtype=torch.float32)

                    heatmap = self.generate_gaussian_heatmap(motor_norm, self.new_size)
                    voxel_spacing = self.size_map[tomo_id]['Voxel spacing']
                    orig_height = self.size_map[tomo_id]['Array shape (axis 1)']
                    orig_width = self.size_map[tomo_id]['Array shape (axis 2)']
                    target_size_pixels_y = 1000.0 / voxel_spacing
                    target_size_pixels_x = 1000.0 / voxel_spacing
                    size_target = torch.tensor([
                        target_size_pixels_y / orig_height,
                        target_size_pixels_x / orig_width
                    ], dtype=torch.float32)
                    offset_target = torch.zeros(2, dtype=torch.float32)

                    if not self.is_test:
                        img_aug = self.image_augment(img)
                        stacked = torch.stack([img_aug[0], heatmap], dim=0)
                        stacked_aug = self.spatial_augment(stacked)
                        img = stacked_aug[0].unsqueeze(0)
                        heatmap = stacked_aug[1]
                        peak_idx = heatmap.view(-1).argmax()
                        y_new = peak_idx // self.new_size[1]
                        x_new = peak_idx % self.new_size[1]
                        motor_norm = torch.tensor([y_new / self.new_size[0], x_new / self.new_size[1]], dtype=torch.float32)

                    self.data.append({
                        'tomo_id': tomo_id,
                        'slice': img,
                        'heatmap': heatmap,
                        'size': size_target,
                        'offset': offset_target,
                        'center': motor_norm,
                        'z': z,
                        'orig_shape': torch.tensor([self.size_map[tomo_id]['Array shape (axis 1)'],
                                                  self.size_map[tomo_id]['Array shape (axis 2)'],
                                                  num_slices], dtype=torch.float32),
                        'voxel_spacing': self.size_map[tomo_id]['Voxel spacing'],
                        'motor': torch.tensor(motor, dtype=torch.float32)
                    })
                    slices_added += 1

                if slices_added == 0:
                    logger.warning(f"Tomogram {tomo_id} has no valid slices in trust region (z={z_start} to {z_end-1}), skipping")
                    skipped_tomograms.append(tomo_id)
                else:
                    logger.debug(f"Processed tomogram {tomo_id}: Added {slices_added} slices (z={z_start} to {z_end-1})")

            logger.info(f"Training dataset initialized: {len(self.data)} slices from {len(tomo_ids) - len(skipped_tomograms)} tomograms, {len(skipped_tomograms)} tomograms skipped")
            if skipped_tomograms:
                logger.warning(f"Skipped tomograms: {sorted(skipped_tomograms)}")
        else:
            for tomo_id in tqdm(self.tomo_ids, desc="Loading test data"):
                files = sorted(self.root_dir.joinpath(tomo_id).glob('*.jpg'))
                num_slices = len(files)
                if num_slices == 0:
                    logger.warning(f"Test tomogram {tomo_id} has no slices in {self.root_dir.joinpath(tomo_id)}, skipping")
                    continue
                orig_shape = torch.tensor([Image.open(files[0]).size[1], Image.open(files[0]).size[0], num_slices], dtype=torch.float32)
                for z, file in enumerate(files):
                    self.data.append({
                        'tomo_id': tomo_id,
                        'slice_path': str(file),
                        'z': z,
                        'orig_shape': orig_shape
                    })
                logger.debug(f"Test tomogram {tomo_id}: Loaded {num_slices} slices")
            logger.info(f"Test dataset initialized: {len(self.data)} slices from {len(tomo_ids)} tomograms")

    def generate_gaussian_heatmap(self, center, xy_size, sigma=4.0):
        heatmap = torch.zeros(xy_size)
        yc, xc = center
        yc = yc * xy_size[0]
        xc = xc * xy_size[1]
        y_coords, x_coords = torch.meshgrid(
            torch.arange(xy_size[0], dtype=torch.float32),
            torch.arange(xy_size[1], dtype=torch.float32),
            indexing='ij'
        )
        dist = ((y_coords - yc) ** 2 + (x_coords - xc) ** 2) / (2.0 * sigma ** 2)
        heatmap = torch.exp(-dist)
        return heatmap

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        item = self.data[idx]
        if self.is_test:
            return {
                'tomo_id': item['tomo_id'],
                'slice_path': item['slice_path'],
                'z': item['z'],
                'orig_shape': item['orig_shape']
            }
        return {
            'tomo_id': item['tomo_id'],
            'slice': item['slice'],
            'heatmap': item['heatmap'].unsqueeze(0),
            'size': item['size'],
            'offset': item['offset'],
            'center': item['center'],
            'z': item['z'],
            'orig_shape': item['orig_shape'],
            'voxel_spacing': item['voxel_spacing'],
            'motor': item['motor']
        }

def custom_collate_fn(batch):
    if 'slice' in batch[0]:
        return {
            'tomo_id': [item['tomo_id'] for item in batch],
            'slice': torch.stack([item['slice'] for item in batch]),
            'heatmap': torch.stack([item['heatmap'] for item in batch]),
            'size': torch.stack([item['size'] for item in batch]),
            'offset': torch.stack([item['offset'] for item in batch]),
            'center': torch.stack([item['center'] for item in batch]),
            'z': torch.tensor([item['z'] for item in batch], dtype=torch.float32),
            'orig_shape': torch.stack([item['orig_shape'] for item in batch]),
            'voxel_spacing': torch.tensor([item['voxel_spacing'] for item in batch], dtype=torch.float32),
            'motor': torch.stack([item['motor'] for item in batch])
        }
    else:
        return {
            'tomo_id': [item['tomo_id'] for item in batch],
            'slice_path': [item['slice_path'] for item in batch],
            'z': torch.tensor([item['z'] for item in batch], dtype=torch.float32),
            'orig_shape': torch.stack([item['orig_shape'] for item in batch])
        }

# Train/validation/test split 
def identify_motor_tomograms(labels_df):
    motor_tomograms = []
    for tomo_id in labels_df["tomo_id"].unique():
        tomo_labels = labels_df[labels_df["tomo_id"] == tomo_id].iloc[0]
        if tomo_labels["Number of motors"] > 0 and tomo_labels["Motor axis 0"] != -1:
            motor_tomograms.append(tomo_id)
    logger.info(f"Found {len(motor_tomograms)} tomograms with motors")
    logger.debug(f"Motor tomogram IDs: {sorted(motor_tomograms)}")
    return motor_tomograms

labels_df = pd.read_csv("/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/train_labels.csv")
tomo_ids = sorted(labels_df["tomo_id"].unique())
train_ids, val_ids = train_test_split(tomo_ids, test_size=0.2, random_state=42)
test_ids = ["tomo_003acc", "tomo_00e047", "tomo_01a877"]
logger.info(f"Total tomograms: {len(tomo_ids)}, Training tomograms: {len(train_ids)}, Validation tomograms: {len(val_ids)}, Test tomograms: {len(test_ids)}")
logger.debug(f"Training tomogram IDs: {sorted(train_ids)}")
logger.debug(f"Validation tomogram IDs: {sorted(val_ids)}")
logger.debug(f"Test tomogram IDs: {sorted(test_ids)}")

# Dataset creation for train val and test
train_dataset = FlagellarDataset(
    tomo_ids=train_ids,
    csv_file='/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/train_labels.csv',
    root_dir='/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/train',
    new_size=(256, 256),
    trust_region=4
)
val_dataset = FlagellarDataset(
    tomo_ids=val_ids,
    csv_file='/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/train_labels.csv',
    root_dir='/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/train',
    new_size=(256, 256),
    trust_region=4
)
test_dataset = FlagellarDataset(
    tomo_ids=test_ids,
    root_dir='/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/test',
    new_size=(256, 256),
    trust_region=4,
    is_test=True
)

# DataLoaders
train_loader = DataLoader(
    train_dataset, batch_size=8, shuffle=True,
    collate_fn=custom_collate_fn, num_workers=0, pin_memory=True
)
val_loader = DataLoader(
    val_dataset, batch_size=8, shuffle=False,
    collate_fn=custom_collate_fn, num_workers=0, pin_memory=True
)

# Model, loss, optimizer
device = 'cuda' if torch.cuda.is_available() else 'cpu'
logger.info(f"Using device: {device}")
model = OptimizedCenterNet2D().to(device)
criterion = CenterNetLoss()
optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)
scaler = torch.cuda.amp.GradScaler()

# Checkpoint loading
start_epoch = 0
best_val_fbeta = 0.0
checkpoint_path = "/kaggle/working/checkpoint.pth"
if os.path.exists(checkpoint_path):
    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)
    model.load_state_dict(checkpoint['model_state_dict'])
    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
    start_epoch = checkpoint['epoch'] + 1
    best_val_fbeta = checkpoint['best_val_fbeta']
    logger.info(f"Resumed from epoch {start_epoch}, best validation F2: {best_val_fbeta}")
else:
    logger.info("No checkpoint found, starting from scratch.")

# Fβ-score calculation
def score(solution, submission, min_radius=1000, beta=2.0):
    solution = solution.sort_values('tomo_id').reset_index(drop=True)
    submission = submission.sort_values('tomo_id').reset_index(drop=True)
    if not solution['tomo_id'].eq(submission['tomo_id']).all():
        raise ValueError('Submitted tomo_id values do not match')
    submission['Has motor'] = 1
    select = (submission[['Motor axis 0', 'Motor axis 1', 'Motor axis 2']] == -1).any(axis='columns')
    submission.loc[select, 'Has motor'] = 0
    coordinate_cols = ['Motor axis 0', 'Motor axis 1', 'Motor axis 2']
    label_tensor = solution[coordinate_cols].values.reshape(len(solution), -1, len(coordinate_cols))
    predicted_tensor = submission[coordinate_cols].values.reshape(len(submission), -1, len(coordinate_cols))
    solution['distance'] = np.linalg.norm(label_tensor - predicted_tensor, axis=2).min(axis=1)
    solution['thresholds'] = solution['Voxel spacing'].apply(lambda x: min_radius / x)
    solution['predictions'] = submission['Has motor'].values
    solution.loc[(solution['distance'] > solution['thresholds']) & (solution['Has motor'] == 1) & (submission['Has motor'] == 1), 'predictions'] = 0
    return fbeta_score(solution['Has motor'].values, solution['predictions'].values, beta=beta)

# Training function
def train_epoch(model, loader, criterion, optimizer, scaler, accum_steps=2, max_grad_norm=1.0):
    model.train()
    train_loss = 0.0
    optimizer.zero_grad()
    tomogram_counts = {}  # Track slices per tomogram
    processed_tomo_ids = set()  # Track unique tomograms
    with warnings.catch_warnings():  # CHANGE in train_epoch (line ~510): Suppress FutureWarning for torch.cuda.amp
        warnings.simplefilter("ignore", category=FutureWarning)
        for i, batch in enumerate(tqdm(loader, desc="Training", file=sys.stdout)):
            slices = batch['slice'].to(device, non_blocking=True)
            heatmaps = batch['heatmap'].to(device, non_blocking=True)
            sizes = batch['size'].to(device, non_blocking=True)
            offsets = batch['offset'].to(device, non_blocking=True)
            tomo_ids = batch['tomo_id']  # List of tomogram IDs in batch
    
            # Log tomogram IDs in batch
            batch_tomo_ids = sorted(set(tomo_ids))
            processed_tomo_ids.update(batch_tomo_ids)
            for tomo_id in tomo_ids:
                tomogram_counts[tomo_id] = tomogram_counts.get(tomo_id, 0) + 1
            logger.debug(f"Batch {i+1}/{len(loader)}, Tomograms: {batch_tomo_ids}, Batch size: {len(tomo_ids)}")
    
            with torch.cuda.amp.autocast():
                pred_heatmaps, pred_sizes, pred_offsets = model(slices)
                loss = criterion(pred_heatmaps, pred_sizes, pred_offsets, heatmaps, sizes, offsets)
                loss = loss / accum_steps
            scaler.scale(loss).backward()
            train_loss += loss.item() * slices.size(0) * accum_steps
            logger.info(f"Batch {i+1}, Loss: {loss.item()*accum_steps:.4f}")
    
            if (i + 1) % accum_steps == 0:
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_grad_norm)
                scaler.step(optimizer)
                scaler.update()
                optimizer.zero_grad()
    
        if (i + 1) % accum_steps != 0:
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_grad_norm)
            scaler.step(optimizer)
            scaler.update()
            optimizer.zero_grad()

    # Summarize tomogram coverage
    logger.info(f"Training epoch: Processed {len(processed_tomo_ids)} unique tomograms, {sum(tomogram_counts.values())} slices")
    logger.debug(f"Tomogram slice counts: {dict(sorted(tomogram_counts.items()))}")
    # Compare with train_ids (assuming train_ids is accessible globally or passed)
    try:
        missing_tomograms = [tid for tid in train_ids if tid not in processed_tomo_ids]
        if missing_tomograms:
            logger.warning(f"Missing {len(missing_tomograms)} tomograms in training: {sorted(missing_tomograms)}")
        else:
            logger.info("All expected tomograms processed in training")
    except NameError:
        logger.warning("train_ids not accessible; cannot check for missing tomograms")

    return train_loss / len(loader.dataset)

# Validation function
def validate(model, loader, criterion, device):
    model.eval()
    val_loss = 0.0
    tomo_predictions = {}
    true_centers = []
    voxel_spacings = []
    with warnings.catch_warnings():  # CHANGE in validate (line ~570): Suppress FutureWarning for torch.cuda.amp
        warnings.simplefilter("ignore", category=FutureWarning)
        with torch.no_grad():
            for batch in tqdm(loader, desc="Validating"):
                slices = batch['slice'].to(device, non_blocking=True)
                heatmaps = batch['heatmap'].to(device, non_blocking=True)
                sizes = batch['size'].to(device, non_blocking=True)
                offsets = batch['offset'].to(device, non_blocking=True)
                centers = batch['center'].to(device, non_blocking=True)
                orig_shapes = batch['orig_shape'].to(device, non_blocking=True)
                voxel_spacings_batch = batch['voxel_spacing'].to(device, non_blocking=True)
                motors = batch['motor'].to(device, non_blocking=True)
                zs = batch['z'].to(device, non_blocking=True)
                tomo_ids = batch['tomo_id']
    
                with torch.cuda.amp.autocast():
                    pred_heatmaps, pred_sizes, pred_offsets = model(slices)
                    loss = criterion(pred_heatmaps, pred_sizes, pred_offsets, heatmaps, sizes, offsets)
                val_loss += loss.item() * slices.size(0)
    
                for i in range(slices.size(0)):
                    tomo_id = tomo_ids[i]
                    confidence = pred_heatmaps[i].max().item()
                    pred_center_norm, _, _ = extract_centroid(pred_heatmaps[i], pred_sizes[i], pred_offsets[i], threshold=0.3)
                    pred_center, _ = denormalize_predictions(pred_center_norm, torch.zeros(2).to(device), zs[i], orig_shapes[i, :2])
                    
                    if tomo_id not in tomo_predictions:
                        tomo_predictions[tomo_id] = []
                    tomo_predictions[tomo_id].append({
                        'Motor axis 0': pred_center[0].item(),
                        'Motor axis 1': pred_center[1].item(),
                        'Motor axis 2': pred_center[2].item(),
                        'confidence': confidence
                    })
                    true_centers.append(motors[i])
                    voxel_spacings.append(voxel_spacings_batch[i])
                    
    # Aggregate predictions per tomogram
    predictions = []
    for tomo_id in val_ids:  # Ensure we process all validation tomograms
        if tomo_id in tomo_predictions and tomo_predictions[tomo_id]:
            # Select the prediction with the highest confidence
            best_pred = max(tomo_predictions[tomo_id], key=lambda x: x['confidence'])
            predictions.append({
                'tomo_id': tomo_id,
                'Motor axis 0': best_pred['Motor axis 0'],
                'Motor axis 1': best_pred['Motor axis 1'],
                'Motor axis 2': best_pred['Motor axis 2']
            })
        else:
            # No valid detections; assume no motor
            predictions.append({
                'tomo_id': tomo_id,
                'Motor axis 0': -1,
                'Motor axis 1': -1,
                'Motor axis 2': -1
            })

    # Create solution and submission DataFrames
    solution_data = []
    for tomo_id in val_ids:
        tomo_labels = labels_df[labels_df['tomo_id'] == tomo_id].iloc[0]
        solution_data.append({
            'tomo_id': tomo_id,
            'Motor axis 0': tomo_labels['Motor axis 0'],
            'Motor axis 1': tomo_labels['Motor axis 1'],
            'Motor axis 2': tomo_labels['Motor axis 2'],
            'Voxel spacing': tomo_labels['Voxel spacing'],
            'Has motor': 1 if tomo_labels['Number of motors'] > 0 else 0
        })
    solution_df = pd.DataFrame(solution_data)
    submission_df = pd.DataFrame(predictions)

    # Verify tomo_id match
    if not solution_df['tomo_id'].eq(submission_df['tomo_id']).all():
        logger.error(f"tomo_id mismatch: solution={solution_df['tomo_id'].tolist()}, submission={submission_df['tomo_id'].tolist()}")
        raise ValueError('Submitted tomo_id values do not match')

    fbeta = score(solution_df, submission_df, min_radius=1000, beta=2)
    logger.info(f"Validation Fβ-score: {fbeta:.4f}")
    return val_loss / len(loader.dataset), fbeta

# Extract centroid (from optimized code)
def extract_centroid(heatmap, size, offset, xy_size=(256, 256), threshold=0.3):
    heatmap = heatmap.squeeze()
    if heatmap.max() < threshold:
        return torch.tensor([-1, -1], dtype=torch.float32, device=heatmap.device), torch.zeros(2, device=heatmap.device), torch.zeros(2, device=heatmap.device)
    peak_value, peak_idx = heatmap.view(-1).topk(1)
    if peak_value < threshold:
        return torch.tensor([-1, -1], dtype=torch.float32, device=heatmap.device), torch.zeros(2, device=heatmap.device), torch.zeros(2, device=heatmap.device)
    y = peak_idx // xy_size[1]
    x = peak_idx % xy_size[1]
    y_norm = torch.clamp(y.float() / xy_size[0], 0, 1)
    x_norm = torch.clamp(x.float() / xy_size[1], 0, 1)
    center = torch.tensor([y_norm, x_norm], dtype=torch.float32, device=heatmap.device)
    pred_size = size[:, y, x].squeeze()
    pred_offset = offset[:, y, x].squeeze()
    center = center + pred_offset
    return center, pred_size, pred_offset

# Denormalize predictions (from optimized code)
def denormalize_predictions(pred_center, pred_size, z, orig_shape):
    pred_center_denorm = torch.zeros(3, dtype=torch.float32, device=pred_center.device)
    pred_center_denorm[0] = z
    pred_center_denorm[1] = pred_center[0] * orig_shape[0]
    pred_center_denorm[2] = pred_center[1] * orig_shape[1]
    pred_size_denorm = pred_size * torch.tensor([orig_shape[0], orig_shape[1]], dtype=torch.float32, device=pred_size.device)
    return pred_center_denorm, pred_size_denorm

# Training loop
num_epochs = 30
patience = 10
trigger_times = 0
train_losses = []
val_losses = []
val_fbetas = []
best_model_path = "/kaggle/working/best_model.pth"

logger.info("Starting training...")
for epoch in range(start_epoch, num_epochs):
    logger.info(f"Starting epoch {epoch+1}/{num_epochs}")
    train_loss = train_epoch(model, train_loader, criterion, optimizer, scaler)
    val_loss, val_fbeta = validate(model, val_loader, criterion, device)
    train_losses.append(train_loss)
    val_losses.append(val_loss)
    val_fbetas.append(val_fbeta)
    scheduler.step()

    logger.info(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Fβ: {val_fbeta:.4f}")

    torch.save({
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'scheduler_state_dict': scheduler.state_dict(),
        'best_val_fbeta': best_val_fbeta,
    }, checkpoint_path)

    if val_fbeta > best_val_fbeta:
        best_val_fbeta = val_fbeta
        trigger_times = 0
        torch.save(model.state_dict(), best_model_path)
        logger.info(f"Saved best model with Val Fβ: {best_val_fbeta:.4f}")
    else:
        trigger_times += 1
        logger.info(f"No improvement in Val Fβ. Epochs without improvement: {trigger_times}/{patience}")
        if trigger_times >= patience:
            logger.info("Early stopping triggered")
            model.load_state_dict(torch.load(best_model_path))
            logger.info(f"Loaded best model with Val Fβ: {best_val_fbeta:.4f}")
            break

    gc.collect()
    torch.cuda.empty_cache()

# Prediction on test set
def process_tomogram(tomo_id, model, test_dataset, device, index=0, total=1, confidence_threshold=0.3):
    logger.info(f"Processing tomogram {tomo_id} ({index}/{total})") 
    tomo_dir = os.path.join('/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/test', tomo_id)
    slice_files = sorted([os.path.join(tomo_dir, f) for f in os.listdir(tomo_dir) if f.endswith('.jpg')])
    num_slices = len(slice_files)

    tomo_data = next(item for item in test_dataset.data if item['tomo_id'] == tomo_id)
    orig_shape = tomo_data['orig_shape']

    all_detections = []
    batch_size = 4 if device.startswith('cuda') else os.cpu_count() * 2

    if device.startswith('cuda'):
        gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9
        free_mem = gpu_mem - torch.cuda.memory_allocated(0) / 1e9
        batch_size = max(4, min(16, int(free_mem / 2)))

    model.eval()
    with torch.no_grad():
        for batch_start in range(0, num_slices, batch_size):
            batch_end = min(batch_start + batch_size, num_slices)
            batch_paths = slice_files[batch_start:batch_end]
            batch_slices = preprocess_batch(batch_paths).to(device)

            with torch.cuda.amp.autocast():
                pred_heatmaps, pred_sizes, pred_offsets = model(batch_slices)

            for i, (heatmap, size, offset) in enumerate(zip(pred_heatmaps, pred_sizes, pred_offsets)):
                confidence = heatmap.max().item()
                if confidence >= confidence_threshold:
                    pred_center_norm, pred_size_norm, _ = extract_centroid(heatmap, size, offset, threshold=confidence_threshold)
                    z = batch_start + i
                    pred_center, pred_size = denormalize_predictions(pred_center_norm, pred_size_norm, z, orig_shape[:2])
                    all_detections.append({
                        'z': z,
                        'y': pred_center[1].item(),
                        'x': pred_center[2].item(),
                        'confidence': confidence,
                        'width': pred_size[1].item(),
                        'height': pred_size[0].item()
                    })

    logger.info(f"Processing tomogram {tomo_id}: Applying 3D NMS with distance_threshold=0.1")  # CHANGE in process_tomogram (line ~764): Added logging to track NMS application
    final_detections = perform_3d_nms(all_detections, distance_threshold=0.1)  # CHANGE in process_tomogram (line ~766): Fixed TypeError by changing nms_threshold to distance_threshold
    logger.info(f"Tomogram {tomo_id}: {len(final_detections)} detections after NMS")  # CHANGE in process_tomogram (line ~767): Added logging to report NMS results
    if not final_detections:
        logger.warning(f"Tomogram {tomo_id}: No detections after NMS, returning default (-1, -1, -1)")  # CHANGE in process_tomogram (line ~768): Added logging for default case
        return {'tomo_id': tomo_id, 'Motor axis 0': -1, 'Motor axis 1': -1, 'Motor axis 2': -1}

    final_detections.sort(key=lambda x: x['confidence'], reverse=True)
    best_detection = final_detections[0]

    return {
        'tomo_id': tomo_id,
        'Motor axis 0': round(best_detection['z']),  # CHANGE in process_tomogram (line ~773): Kept original author's rounding for consistency with submission format
        'Motor axis 1': round(best_detection['y']),  # CHANGE in process_tomogram (line ~774): Kept original author's rounding for consistency with submission format
        'Motor axis 2': round(best_detection['x'])   # CHANGE in process_tomogram (line ~775): Kept original author's rounding for consistency with submission format
    }

def preprocess_batch(slice_paths, new_size=(256, 256)):
    images = []
    for path in slice_paths:
        img = Image.open(path).convert('L')
        img = T.functional.resize(img, new_size)
        img = T.functional.to_tensor(img)
        img = (img - img.mean()) / (img.std() + 1e-8)
        images.append(img)
    return torch.stack(images)

def perform_3d_nms(detections, distance_threshold=0.1): 
    if not detections:
        return []
    detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)
    final_detections = []
    def distance_3d(d1, d2):
        return np.sqrt((d1['z'] - d2['z'])**2 + (d1['y'] - d2['y'])**2 + (d1['x'] - d2['x'])**2)
    trust_region = 4
    threshold = trust_region * distance_threshold
    while detections:
        best_detection = detections.pop(0)
        final_detections.append(best_detection)
        detections = [d for d in detections if distance_3d(d, best_detection) > threshold]
    return final_detections


def generate_submission(test_dataset, model, device):
    logger.info("Starting generate_submission")
    total_tomos = len(test_dataset.tomo_ids)
    model.to(device)
    if device.startswith('cuda'):
        try:
            model.half()
            logger.info("Using FP16 for inference")
        except:
            logger.info("FP16 not supported")
    results = []
    with ThreadPoolExecutor(max_workers=1) as executor:
        args_list = [(tomo_id, model, test_dataset, device, i + 1, total_tomos) 
                     for i, tomo_id in enumerate(test_dataset.tomo_ids)]
        results = list(executor.map(process_tomogram_wrapper, args_list))
    submission_df = pd.DataFrame(results, columns=['tomo_id', 'Motor axis 0', 'Motor axis 1', 'Motor axis 2'])
    submission_df.to_csv('/kaggle/working/submission.csv', index=False)
    motors_found = sum(1 for r in results if r['Motor axis 0'] != -1)
    logger.info(f"Submission saved. Motors detected: {motors_found}/{total_tomos}")
    return submission_df

def process_tomogram_wrapper(args):
    tomo_id, model, test_dataset, device, index, total = args  
    return process_tomogram(tomo_id, model, test_dataset, device, index, total)

# Run the pipeline
start_time = time.time()
logger.info("Starting training...")
model.train()
for epoch in range(start_epoch, num_epochs):
    train_loss = train_epoch(model, train_loader, criterion, optimizer, scaler)
    val_loss, val_fbeta = validate(model, val_loader, criterion, device)
    logger.info(f"Epoch {epoch+1}/{num_epochs} completed. Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Fβ: {val_fbeta:.4f}")
logger.info("Generating test predictions...")
submission_df = generate_submission(test_dataset, model, device)
logger.info(f"Total execution time: {(time.time() - start_time)/60:.2f} minutes")
logger.info("Pipeline completed")  # CHANGE in training loop (line ~680): Added logging to confirm pipeline completion
sys.stdout.flush()  # CHANGE in training loop (line ~681): Added flush to ensure logs are written immediately
