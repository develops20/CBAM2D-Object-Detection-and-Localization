{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "379a85b7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-26T08:39:58.754012Z",
     "iopub.status.busy": "2025-05-26T08:39:58.753769Z",
     "iopub.status.idle": "2025-05-26T09:02:05.330291Z",
     "shell.execute_reply": "2025-05-26T09:02:05.329681Z"
    },
    "papermill": {
     "duration": 1326.582548,
     "end_time": "2025-05-26T09:02:05.331777",
     "exception": false,
     "start_time": "2025-05-26T08:39:58.749229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading training data: 100%|██████████| 316/316 [01:07<00:00,  4.71it/s]\n",
      "Loading training data: 100%|██████████| 46/46 [00:09<00:00,  4.72it/s]\n",
      "Loading test data: 100%|██████████| 3/3 [00:00<00:00, 47.03it/s]\n",
      "/tmp/ipykernel_19/2536492568.py:473: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:33<00:00, 10.46it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 26.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 11.00it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 29.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.96it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 29.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.96it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 29.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.96it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.92it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 27.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.92it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.92it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.92it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.94it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.94it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.94it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.94it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.94it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 27.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.94it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 27.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.96it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 28.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 27.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.94it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 27.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.94it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 27.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 355/355 [00:32<00:00, 10.94it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 52/52 [00:01<00:00, 27.98it/s]\n",
      "/tmp/ipykernel_19/2536492568.py:755: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pathlib import Path\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import fbeta_score\n",
    "import warnings # to suppress FutureWarning cuda warnings \n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure logging\n",
    "logger = logging.getLogger('')\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.handlers = []\n",
    "file_handler = logging.FileHandler(\"/kaggle/working/training.log\", mode='w')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "logger.addHandler(file_handler)\n",
    "console_handler = logging.StreamHandler(sys.stdout)\n",
    "console_handler.setLevel(logging.ERROR)\n",
    "console_handler.setFormatter(logging.Formatter('%(levelname)s - %(message)s'))\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "\n",
    "# MultiHeadSelfAttention\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, in_channels, num_heads=8):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        assert in_channels % num_heads == 0, \"in_channels must be divisible by num_heads\"\n",
    "        self.in_channels = in_channels\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = in_channels // num_heads\n",
    "        self.query = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "        self.key = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "        self.value = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "        self.out_proj = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, channels, height, width = x.size()\n",
    "        n_pixels = height * width\n",
    "        proj_query = self.query(x).view(batch, self.num_heads, self.head_dim, n_pixels).permute(0, 1, 3, 2)\n",
    "        proj_key = self.key(x).view(batch, self.num_heads, self.head_dim, n_pixels)\n",
    "        proj_value = self.value(x).view(batch, self.num_heads, self.head_dim, n_pixels).permute(0, 1, 3, 2)\n",
    "        energy = torch.matmul(proj_query, proj_key) / (self.head_dim ** 0.5)\n",
    "        energy = torch.clamp(energy, min=-10, max=10)\n",
    "        attention = self.softmax(energy)\n",
    "        out = torch.matmul(attention, proj_value)\n",
    "        out = out.permute(0, 1, 3, 2).contiguous().view(batch, self.in_channels, height, width)\n",
    "        out = self.out_proj(out)\n",
    "        return self.gamma * out + x\n",
    "\n",
    "# EnhancedCABM2D\n",
    "class EnhancedCABM2D(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super(EnhancedCABM2D, self).__init__()\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(in_channels, in_channels // reduction, kernel_size=1)\n",
    "        self.fc2 = nn.Conv2d(in_channels // reduction, in_channels, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.conv_spatial1 = nn.Conv2d(in_channels, 1, kernel_size=7, padding=3, dilation=1, bias=False)\n",
    "        self.conv_spatial2 = nn.Conv2d(in_channels, 1, kernel_size=7, padding=9, dilation=3, bias=False)\n",
    "        self.conv_refine = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.self_attention = MultiHeadSelfAttention(in_channels, num_heads=8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        channel_avg = self.global_pool(x)\n",
    "        channel_att = self.fc1(channel_avg)\n",
    "        channel_att = self.relu(channel_att)\n",
    "        channel_att = self.fc2(channel_att)\n",
    "        channel_att = self.sigmoid(channel_att)\n",
    "        x_channel = x * channel_att\n",
    "        spatial_att1 = self.conv_spatial1(x_channel)\n",
    "        spatial_att2 = self.conv_spatial2(x_channel)\n",
    "        spatial_att = self.sigmoid(spatial_att1 + spatial_att2)\n",
    "        x_spatial = x_channel * spatial_att\n",
    "        x_self_att = self.self_attention(x_spatial)\n",
    "        x_refined = self.conv_refine(x_self_att)\n",
    "        x_refined = self.bn(x_refined)\n",
    "        x_refined = self.relu(x_refined)\n",
    "        return x + x_refined\n",
    "\n",
    "# OptimizedCenterNet2D\n",
    "class OptimizedCenterNet2D(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super(OptimizedCenterNet2D, self).__init__()\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.enc3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.enc4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1, stride=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.attention = EnhancedCABM2D(in_channels=256)\n",
    "        self.dec4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.dec3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.heatmap_head = nn.Sequential(\n",
    "            nn.Conv2d(32, out_channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.size_head = nn.Conv2d(32, 2, kernel_size=1)\n",
    "        self.offset_head = nn.Conv2d(32, 2, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(e1)\n",
    "        e3 = self.enc3(e2)\n",
    "        e4 = self.enc4(e3)\n",
    "        e4_att = self.attention(e4)\n",
    "        d4 = self.dec4(e4_att) + e3\n",
    "        d3 = self.dec3(d4) + e2\n",
    "        d2 = self.dec2(d3) + e1\n",
    "        heatmap = self.heatmap_head(d2)\n",
    "        size = self.size_head(d2)\n",
    "        offset = self.offset_head(d2)\n",
    "        return heatmap, size, offset\n",
    "\n",
    "# CenterNetLoss\n",
    "class CenterNetLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, size_weight=0.5, offset_weight=0.1):\n",
    "        super(CenterNetLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.size_weight = size_weight\n",
    "        self.offset_weight = offset_weight\n",
    "\n",
    "    def gaussian_focal_loss(self, pred_heatmap, target_heatmap):\n",
    "        pos_loss = -target_heatmap * (1 - pred_heatmap) ** self.gamma * torch.log(pred_heatmap + 1e-6)\n",
    "        neg_loss = -(1 - target_heatmap) * pred_heatmap ** self.gamma * torch.log(1 - pred_heatmap + 1e-6)\n",
    "        loss = (pos_loss + neg_loss).sum() / pred_heatmap.size(0)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, pred_heatmap, pred_size, pred_offset, target_heatmap, target_size, target_offset):\n",
    "        gfl = self.gaussian_focal_loss(pred_heatmap, target_heatmap)\n",
    "        batch_size = pred_heatmap.size(0)\n",
    "        pred_size_at_centers = torch.zeros(batch_size, 2, device=pred_heatmap.device)\n",
    "        pred_offset_at_centers = torch.zeros(batch_size, 2, device=pred_heatmap.device)\n",
    "        for i in range(batch_size):\n",
    "            heatmap = pred_heatmap[i].squeeze()\n",
    "            peak_idx = heatmap.view(-1).argmax()\n",
    "            y = peak_idx // 256\n",
    "            x = peak_idx % 256\n",
    "            pred_size_at_centers[i] = pred_size[i, :, y, x]\n",
    "            pred_offset_at_centers[i] = pred_offset[i, :, y, x]\n",
    "        size_loss = F.mse_loss(pred_size_at_centers, target_size, reduction='mean') * self.size_weight\n",
    "        offset_loss = F.mse_loss(pred_offset_at_centers, target_offset, reduction='mean') * self.offset_weight\n",
    "        return gfl + size_loss + offset_loss\n",
    "\n",
    "\n",
    "# FlagellarDataset - storage containing image tensors, heatmaps, sizes, offfsets and metadata\n",
    "class FlagellarDataset(Dataset):\n",
    "    def __init__(self, tomo_ids, csv_file=None, root_dir=None, new_size=(256, 256), trust_region=4, is_test=False):\n",
    "        self.tomo_ids = tomo_ids\n",
    "        self.csv_file = csv_file\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.new_size = new_size\n",
    "        self.trust_region = trust_region\n",
    "        self.is_test = is_test\n",
    "        self.data = []\n",
    "        self.spatial_augment = T.Compose([\n",
    "            T.RandomHorizontalFlip(p=0.5),\n",
    "            T.RandomRotation(degrees=10),\n",
    "            T.RandomAffine(degrees=0, scale=(0.95, 1.05))\n",
    "        ])\n",
    "        self.image_augment = T.Compose([\n",
    "            T.RandomApply([T.ColorJitter(brightness=0.1, contrast=0.1)], p=0.2)\n",
    "        ])\n",
    "        logger.info(f\"Initializing {'test' if is_test else 'train/val'} dataset with {len(tomo_ids)} tomograms, is_test={is_test}\")\n",
    "\n",
    "        if csv_file and os.path.exists(csv_file) and not is_test:\n",
    "            labels = pd.read_csv(csv_file)\n",
    "            self.motors_map = labels.groupby('tomo_id').apply(\n",
    "                lambda g: np.array(g[['Motor axis 0', 'Motor axis 1', 'Motor axis 2']].values[0], dtype=np.float32),\n",
    "                include_groups=False\n",
    "            ).to_dict()\n",
    "            self.size_map = labels.groupby('tomo_id').agg({\n",
    "                'Array shape (axis 1)': 'first',\n",
    "                'Array shape (axis 2)': 'first',\n",
    "                'Array shape (axis 0)': 'first',\n",
    "                'Voxel spacing': 'first'\n",
    "            }).to_dict('index')\n",
    "            logger.info(f\"Loaded labels for {len(self.motors_map)} tomograms from {csv_file}\")\n",
    "\n",
    "            skipped_tomograms = []\n",
    "            for tomo_id in tqdm(self.tomo_ids, desc=\"Loading training data\"):\n",
    "                if tomo_id not in self.motors_map:\n",
    "                    logger.warning(f\"Tomogram {tomo_id} not in labels, skipping. Available tomo_ids: {sorted(list(self.motors_map.keys()))[:10]}...\")\n",
    "                    skipped_tomograms.append(tomo_id)\n",
    "                    continue\n",
    "                \n",
    "                tomo_dir = self.root_dir.joinpath(tomo_id)\n",
    "                if not tomo_dir.exists():\n",
    "                    logger.warning(f\"Tomogram {tomo_id} directory {tomo_dir} does not exist, skipping\")\n",
    "                    skipped_tomograms.append(tomo_id)\n",
    "                    continue\n",
    "\n",
    "                motor = self.motors_map[tomo_id]\n",
    "                if np.all(motor == -1):\n",
    "                    logger.warning(f\"Tomogram {tomo_id} has invalid motor coordinates {motor.tolist()}, skipping\")\n",
    "                    skipped_tomograms.append(tomo_id)\n",
    "                    continue\n",
    "\n",
    "                files = sorted(tomo_dir.glob('*.jpg'))\n",
    "                num_slices = len(files)\n",
    "                if num_slices == 0:\n",
    "                    logger.warning(f\"Tomogram {tomo_id} has no slices in {tomo_dir}, skipping\")\n",
    "                    skipped_tomograms.append(tomo_id)\n",
    "                    continue\n",
    "\n",
    "                center_z = int(motor[0])\n",
    "                z_start = max(0, center_z - self.trust_region)\n",
    "                z_end = min(num_slices, center_z + self.trust_region + 1)\n",
    "                slices_added = 0\n",
    "\n",
    "                for z in range(z_start, z_end):\n",
    "                    slice_path = files[z] if z < len(files) else None\n",
    "                    if not slice_path or not slice_path.exists():\n",
    "                        logger.debug(f\"Tomogram {tomo_id}, slice {z} not found at {slice_path or tomo_dir}, skipping slice\")\n",
    "                        continue\n",
    "\n",
    "                    img = Image.open(slice_path).convert('L')\n",
    "                    img = T.functional.resize(img, new_size)\n",
    "                    img = T.functional.to_tensor(img)\n",
    "                    img = (img - img.mean()) / (img.std() + 1e-8)\n",
    "\n",
    "                    motor_norm = torch.tensor([\n",
    "                        motor[1] / self.size_map[tomo_id]['Array shape (axis 1)'],\n",
    "                        motor[2] / self.size_map[tomo_id]['Array shape (axis 2)']\n",
    "                    ], dtype=torch.float32)\n",
    "\n",
    "                    heatmap = self.generate_gaussian_heatmap(motor_norm, self.new_size)\n",
    "                    voxel_spacing = self.size_map[tomo_id]['Voxel spacing']\n",
    "                    orig_height = self.size_map[tomo_id]['Array shape (axis 1)']\n",
    "                    orig_width = self.size_map[tomo_id]['Array shape (axis 2)']\n",
    "                    target_size_pixels_y = 1000.0 / voxel_spacing\n",
    "                    target_size_pixels_x = 1000.0 / voxel_spacing\n",
    "                    size_target = torch.tensor([\n",
    "                        target_size_pixels_y / orig_height,\n",
    "                        target_size_pixels_x / orig_width\n",
    "                    ], dtype=torch.float32)\n",
    "                    offset_target = torch.zeros(2, dtype=torch.float32)\n",
    "\n",
    "                    if not self.is_test:\n",
    "                        img_aug = self.image_augment(img)\n",
    "                        stacked = torch.stack([img_aug[0], heatmap], dim=0)\n",
    "                        stacked_aug = self.spatial_augment(stacked)\n",
    "                        img = stacked_aug[0].unsqueeze(0)\n",
    "                        heatmap = stacked_aug[1]\n",
    "                        peak_idx = heatmap.view(-1).argmax()\n",
    "                        y_new = peak_idx // self.new_size[1]\n",
    "                        x_new = peak_idx % self.new_size[1]\n",
    "                        motor_norm = torch.tensor([y_new / self.new_size[0], x_new / self.new_size[1]], dtype=torch.float32)\n",
    "\n",
    "                    self.data.append({\n",
    "                        'tomo_id': tomo_id,\n",
    "                        'slice': img,\n",
    "                        'heatmap': heatmap,\n",
    "                        'size': size_target,\n",
    "                        'offset': offset_target,\n",
    "                        'center': motor_norm,\n",
    "                        'z': z,\n",
    "                        'orig_shape': torch.tensor([self.size_map[tomo_id]['Array shape (axis 1)'],\n",
    "                                                  self.size_map[tomo_id]['Array shape (axis 2)'],\n",
    "                                                  num_slices], dtype=torch.float32),\n",
    "                        'voxel_spacing': self.size_map[tomo_id]['Voxel spacing'],\n",
    "                        'motor': torch.tensor(motor, dtype=torch.float32)\n",
    "                    })\n",
    "                    slices_added += 1\n",
    "\n",
    "                if slices_added == 0:\n",
    "                    logger.warning(f\"Tomogram {tomo_id} has no valid slices in trust region (z={z_start} to {z_end-1}), skipping\")\n",
    "                    skipped_tomograms.append(tomo_id)\n",
    "                else:\n",
    "                    logger.debug(f\"Processed tomogram {tomo_id}: Added {slices_added} slices (z={z_start} to {z_end-1})\")\n",
    "\n",
    "            logger.info(f\"Training dataset initialized: {len(self.data)} slices from {len(tomo_ids) - len(skipped_tomograms)} tomograms, {len(skipped_tomograms)} tomograms skipped\")\n",
    "            if skipped_tomograms:\n",
    "                logger.warning(f\"Skipped tomograms: {sorted(skipped_tomograms)}\")\n",
    "        else:\n",
    "            for tomo_id in tqdm(self.tomo_ids, desc=\"Loading test data\"):\n",
    "                files = sorted(self.root_dir.joinpath(tomo_id).glob('*.jpg'))\n",
    "                num_slices = len(files)\n",
    "                if num_slices == 0:\n",
    "                    logger.warning(f\"Test tomogram {tomo_id} has no slices in {self.root_dir.joinpath(tomo_id)}, skipping\")\n",
    "                    continue\n",
    "                orig_shape = torch.tensor([Image.open(files[0]).size[1], Image.open(files[0]).size[0], num_slices], dtype=torch.float32)\n",
    "                for z, file in enumerate(files):\n",
    "                    self.data.append({\n",
    "                        'tomo_id': tomo_id,\n",
    "                        'slice_path': str(file),\n",
    "                        'z': z,\n",
    "                        'orig_shape': orig_shape\n",
    "                    })\n",
    "                logger.debug(f\"Test tomogram {tomo_id}: Loaded {num_slices} slices\")\n",
    "            logger.info(f\"Test dataset initialized: {len(self.data)} slices from {len(tomo_ids)} tomograms\")\n",
    "\n",
    "    def generate_gaussian_heatmap(self, center, xy_size, sigma=4.0):\n",
    "        heatmap = torch.zeros(xy_size)\n",
    "        yc, xc = center\n",
    "        yc = yc * xy_size[0]\n",
    "        xc = xc * xy_size[1]\n",
    "        y_coords, x_coords = torch.meshgrid(\n",
    "            torch.arange(xy_size[0], dtype=torch.float32),\n",
    "            torch.arange(xy_size[1], dtype=torch.float32),\n",
    "            indexing='ij'\n",
    "        )\n",
    "        dist = ((y_coords - yc) ** 2 + (x_coords - xc) ** 2) / (2.0 * sigma ** 2)\n",
    "        heatmap = torch.exp(-dist)\n",
    "        return heatmap\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        if self.is_test:\n",
    "            return {\n",
    "                'tomo_id': item['tomo_id'],\n",
    "                'slice_path': item['slice_path'],\n",
    "                'z': item['z'],\n",
    "                'orig_shape': item['orig_shape']\n",
    "            }\n",
    "        return {\n",
    "            'tomo_id': item['tomo_id'],\n",
    "            'slice': item['slice'],\n",
    "            'heatmap': item['heatmap'].unsqueeze(0),\n",
    "            'size': item['size'],\n",
    "            'offset': item['offset'],\n",
    "            'center': item['center'],\n",
    "            'z': item['z'],\n",
    "            'orig_shape': item['orig_shape'],\n",
    "            'voxel_spacing': item['voxel_spacing'],\n",
    "            'motor': item['motor']\n",
    "        }\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    if 'slice' in batch[0]:\n",
    "        return {\n",
    "            'tomo_id': [item['tomo_id'] for item in batch],\n",
    "            'slice': torch.stack([item['slice'] for item in batch]),\n",
    "            'heatmap': torch.stack([item['heatmap'] for item in batch]),\n",
    "            'size': torch.stack([item['size'] for item in batch]),\n",
    "            'offset': torch.stack([item['offset'] for item in batch]),\n",
    "            'center': torch.stack([item['center'] for item in batch]),\n",
    "            'z': torch.tensor([item['z'] for item in batch], dtype=torch.float32),\n",
    "            'orig_shape': torch.stack([item['orig_shape'] for item in batch]),\n",
    "            'voxel_spacing': torch.tensor([item['voxel_spacing'] for item in batch], dtype=torch.float32),\n",
    "            'motor': torch.stack([item['motor'] for item in batch])\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'tomo_id': [item['tomo_id'] for item in batch],\n",
    "            'slice_path': [item['slice_path'] for item in batch],\n",
    "            'z': torch.tensor([item['z'] for item in batch], dtype=torch.float32),\n",
    "            'orig_shape': torch.stack([item['orig_shape'] for item in batch])\n",
    "        }\n",
    "\n",
    "# Train/validation/test split \n",
    "def identify_motor_tomograms(labels_df):\n",
    "    motor_tomograms = []\n",
    "    for tomo_id in labels_df[\"tomo_id\"].unique():\n",
    "        tomo_labels = labels_df[labels_df[\"tomo_id\"] == tomo_id].iloc[0]\n",
    "        if tomo_labels[\"Number of motors\"] > 0 and tomo_labels[\"Motor axis 0\"] != -1:\n",
    "            motor_tomograms.append(tomo_id)\n",
    "    logger.info(f\"Found {len(motor_tomograms)} tomograms with motors\")\n",
    "    logger.debug(f\"Motor tomogram IDs: {sorted(motor_tomograms)}\")\n",
    "    return motor_tomograms\n",
    "\n",
    "labels_df = pd.read_csv(\"/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/train_labels.csv\")\n",
    "tomo_ids = sorted(labels_df[\"tomo_id\"].unique())\n",
    "motor_tomo_ids = identify_motor_tomograms(labels_df)\n",
    "logger.info(f\"Total tomograms: {len(tomo_ids)}, Motor tomograms: {len(motor_tomo_ids)}\")\n",
    "valid_motors = labels_df[labels_df['Motor axis 0'] != -1]['tomo_id'].tolist()\n",
    "train_val_ids = [tid for tid in tomo_ids if tid in valid_motors]\n",
    "train_ids, val_ids = train_test_split(train_val_ids, test_size=0.125, random_state=42)\n",
    "test_ids = [\"tomo_003acc\", \"tomo_00e047\", \"tomo_01a877\"]\n",
    "logger.info(f\"Dataset split: {len(train_ids)} training tomograms, {len(val_ids)} validation tomograms, {len(test_ids)} test tomograms\")\n",
    "logger.info(f\"Test IDs: {test_ids}\")\n",
    "logger.debug(f\"Training tomogram IDs: {sorted(train_ids)}\")\n",
    "logger.debug(f\"Validation tomogram IDs: {sorted(val_ids)}\")\n",
    "logger.debug(f\"Test tomogram IDs: {sorted(test_ids)}\")\n",
    "\n",
    "# Dataset creation for train val and test\n",
    "train_dataset = FlagellarDataset(\n",
    "    tomo_ids=train_ids,\n",
    "    csv_file='/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/train_labels.csv',\n",
    "    root_dir='/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/train',\n",
    "    new_size=(256, 256),\n",
    "    trust_region=4\n",
    ")\n",
    "val_dataset = FlagellarDataset(\n",
    "    tomo_ids=val_ids,\n",
    "    csv_file='/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/train_labels.csv',\n",
    "    root_dir='/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/train',\n",
    "    new_size=(256, 256),\n",
    "    trust_region=4\n",
    ")\n",
    "test_dataset = FlagellarDataset(\n",
    "    tomo_ids=test_ids,\n",
    "    root_dir='/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/test',\n",
    "    new_size=(256, 256),\n",
    "    trust_region=4,\n",
    "    is_test=True\n",
    ")\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=8, shuffle=True,\n",
    "    collate_fn=custom_collate_fn, num_workers=0, pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=8, shuffle=False,\n",
    "    collate_fn=custom_collate_fn, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "# Model, loss, optimizer\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "logger.info(f\"Using device: {device}\")\n",
    "model = OptimizedCenterNet2D().to(device)\n",
    "criterion = CenterNetLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Checkpoint loading\n",
    "start_epoch = 0\n",
    "best_val_fbeta = 0.0\n",
    "checkpoint_path = \"/kaggle/working/checkpoint.pth\"\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_val_fbeta = checkpoint['best_val_fbeta']\n",
    "    logger.info(f\"Resumed from epoch {start_epoch}, best validation F2: {best_val_fbeta}\")\n",
    "else:\n",
    "    logger.info(\"No checkpoint found, starting from scratch.\")\n",
    "\n",
    "# Fβ-score calculation\n",
    "def score(solution, submission, min_radius=1000, beta=2.0):\n",
    "    solution = solution.sort_values('tomo_id').reset_index(drop=True)\n",
    "    submission = submission.sort_values('tomo_id').reset_index(drop=True)\n",
    "    if not solution['tomo_id'].eq(submission['tomo_id']).all():\n",
    "        raise ValueError('Submitted tomo_id values do not match')\n",
    "    submission['Has motor'] = 1\n",
    "    select = (submission[['Motor axis 0', 'Motor axis 1', 'Motor axis 2']] == -1).any(axis='columns')\n",
    "    submission.loc[select, 'Has motor'] = 0\n",
    "    coordinate_cols = ['Motor axis 0', 'Motor axis 1', 'Motor axis 2']\n",
    "    label_tensor = solution[coordinate_cols].values.reshape(len(solution), -1, len(coordinate_cols))\n",
    "    predicted_tensor = submission[coordinate_cols].values.reshape(len(submission), -1, len(coordinate_cols))\n",
    "    solution['distance'] = np.linalg.norm(label_tensor - predicted_tensor, axis=2).min(axis=1)\n",
    "    solution['thresholds'] = solution['Voxel spacing'].apply(lambda x: min_radius / x)\n",
    "    solution['predictions'] = submission['Has motor'].values\n",
    "    solution.loc[(solution['distance'] > solution['thresholds']) & (solution['Has motor'] == 1) & (submission['Has motor'] == 1), 'predictions'] = 0\n",
    "    return fbeta_score(solution['Has motor'].values, solution['predictions'].values, beta=beta)\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, loader, criterion, optimizer, scaler, accum_steps=2, max_grad_norm=1.0):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "    tomogram_counts = {}  # Track slices per tomogram\n",
    "    processed_tomo_ids = set()  # Track unique tomograms\n",
    "    with warnings.catch_warnings():  # CHANGE in train_epoch (line ~510): Suppress FutureWarning for torch.cuda.amp\n",
    "        warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "        for i, batch in enumerate(tqdm(loader, desc=\"Training\", file=sys.stdout)):\n",
    "            slices = batch['slice'].to(device, non_blocking=True)\n",
    "            heatmaps = batch['heatmap'].to(device, non_blocking=True)\n",
    "            sizes = batch['size'].to(device, non_blocking=True)\n",
    "            offsets = batch['offset'].to(device, non_blocking=True)\n",
    "            tomo_ids = batch['tomo_id']  # List of tomogram IDs in batch\n",
    "    \n",
    "            # Log tomogram IDs in batch\n",
    "            batch_tomo_ids = sorted(set(tomo_ids))\n",
    "            processed_tomo_ids.update(batch_tomo_ids)\n",
    "            for tomo_id in tomo_ids:\n",
    "                tomogram_counts[tomo_id] = tomogram_counts.get(tomo_id, 0) + 1\n",
    "            logger.debug(f\"Batch {i+1}/{len(loader)}, Tomograms: {batch_tomo_ids}, Batch size: {len(tomo_ids)}\")\n",
    "    \n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred_heatmaps, pred_sizes, pred_offsets = model(slices)\n",
    "                loss = criterion(pred_heatmaps, pred_sizes, pred_offsets, heatmaps, sizes, offsets)\n",
    "                loss = loss / accum_steps\n",
    "            scaler.scale(loss).backward()\n",
    "            train_loss += loss.item() * slices.size(0) * accum_steps\n",
    "            logger.info(f\"Batch {i+1}, Loss: {loss.item()*accum_steps:.4f}\")\n",
    "    \n",
    "            if (i + 1) % accum_steps == 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_grad_norm)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "    \n",
    "        if (i + 1) % accum_steps != 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_grad_norm)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    # Summarize tomogram coverage\n",
    "    logger.info(f\"Training epoch: Processed {len(processed_tomo_ids)} unique tomograms, {sum(tomogram_counts.values())} slices\")\n",
    "    logger.debug(f\"Tomogram slice counts: {dict(sorted(tomogram_counts.items()))}\")\n",
    "    # Compare with train_ids (assuming train_ids is accessible globally or passed)\n",
    "    try:\n",
    "        missing_tomograms = [tid for tid in train_ids if tid not in processed_tomo_ids]\n",
    "        if missing_tomograms:\n",
    "            logger.warning(f\"Missing {len(missing_tomograms)} tomograms in training: {sorted(missing_tomograms)}\")\n",
    "        else:\n",
    "            logger.info(\"All expected tomograms processed in training\")\n",
    "    except NameError:\n",
    "        logger.warning(\"train_ids not accessible; cannot check for missing tomograms\")\n",
    "\n",
    "    return train_loss / len(loader.dataset)\n",
    "\n",
    "# Validation function\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    tomo_predictions = {}\n",
    "    true_centers = []\n",
    "    voxel_spacings = []\n",
    "    with warnings.catch_warnings():  # CHANGE in validate (line ~570): Suppress FutureWarning for torch.cuda.amp\n",
    "        warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(loader, desc=\"Validating\"):\n",
    "                slices = batch['slice'].to(device, non_blocking=True)\n",
    "                heatmaps = batch['heatmap'].to(device, non_blocking=True)\n",
    "                sizes = batch['size'].to(device, non_blocking=True)\n",
    "                offsets = batch['offset'].to(device, non_blocking=True)\n",
    "                centers = batch['center'].to(device, non_blocking=True)\n",
    "                orig_shapes = batch['orig_shape'].to(device, non_blocking=True)\n",
    "                voxel_spacings_batch = batch['voxel_spacing'].to(device, non_blocking=True)\n",
    "                motors = batch['motor'].to(device, non_blocking=True)\n",
    "                zs = batch['z'].to(device, non_blocking=True)\n",
    "                tomo_ids = batch['tomo_id']\n",
    "    \n",
    "                with torch.cuda.amp.autocast():\n",
    "                    pred_heatmaps, pred_sizes, pred_offsets = model(slices)\n",
    "                    loss = criterion(pred_heatmaps, pred_sizes, pred_offsets, heatmaps, sizes, offsets)\n",
    "                val_loss += loss.item() * slices.size(0)\n",
    "    \n",
    "                for i in range(slices.size(0)):\n",
    "                    tomo_id = tomo_ids[i]\n",
    "                    confidence = pred_heatmaps[i].max().item()\n",
    "                    pred_center_norm, _, _ = extract_centroid(pred_heatmaps[i], pred_sizes[i], pred_offsets[i], threshold=0.3)\n",
    "                    pred_center, _ = denormalize_predictions(pred_center_norm, torch.zeros(2).to(device), zs[i], orig_shapes[i, :2])\n",
    "                    \n",
    "                    if tomo_id not in tomo_predictions:\n",
    "                        tomo_predictions[tomo_id] = []\n",
    "                    tomo_predictions[tomo_id].append({\n",
    "                        'Motor axis 0': pred_center[0].item(),\n",
    "                        'Motor axis 1': pred_center[1].item(),\n",
    "                        'Motor axis 2': pred_center[2].item(),\n",
    "                        'confidence': confidence\n",
    "                    })\n",
    "                    true_centers.append(motors[i])\n",
    "                    voxel_spacings.append(voxel_spacings_batch[i])\n",
    "                    \n",
    "    # Aggregate predictions per tomogram\n",
    "    predictions = []\n",
    "    for tomo_id in val_ids:  # Ensure we process all validation tomograms\n",
    "        if tomo_id in tomo_predictions and tomo_predictions[tomo_id]:\n",
    "            # Select the prediction with the highest confidence\n",
    "            best_pred = max(tomo_predictions[tomo_id], key=lambda x: x['confidence'])\n",
    "            predictions.append({\n",
    "                'tomo_id': tomo_id,\n",
    "                'Motor axis 0': best_pred['Motor axis 0'],\n",
    "                'Motor axis 1': best_pred['Motor axis 1'],\n",
    "                'Motor axis 2': best_pred['Motor axis 2']\n",
    "            })\n",
    "        else:\n",
    "            # No valid detections; assume no motor\n",
    "            predictions.append({\n",
    "                'tomo_id': tomo_id,\n",
    "                'Motor axis 0': -1,\n",
    "                'Motor axis 1': -1,\n",
    "                'Motor axis 2': -1\n",
    "            })\n",
    "\n",
    "    # Create solution and submission DataFrames\n",
    "    solution_data = []\n",
    "    for tomo_id in val_ids:\n",
    "        tomo_labels = labels_df[labels_df['tomo_id'] == tomo_id].iloc[0]\n",
    "        solution_data.append({\n",
    "            'tomo_id': tomo_id,\n",
    "            'Motor axis 0': tomo_labels['Motor axis 0'],\n",
    "            'Motor axis 1': tomo_labels['Motor axis 1'],\n",
    "            'Motor axis 2': tomo_labels['Motor axis 2'],\n",
    "            'Voxel spacing': tomo_labels['Voxel spacing'],\n",
    "            'Has motor': 1 if tomo_labels['Number of motors'] > 0 else 0\n",
    "        })\n",
    "    solution_df = pd.DataFrame(solution_data)\n",
    "    submission_df = pd.DataFrame(predictions)\n",
    "\n",
    "    # Verify tomo_id match\n",
    "    if not solution_df['tomo_id'].eq(submission_df['tomo_id']).all():\n",
    "        logger.error(f\"tomo_id mismatch: solution={solution_df['tomo_id'].tolist()}, submission={submission_df['tomo_id'].tolist()}\")\n",
    "        raise ValueError('Submitted tomo_id values do not match')\n",
    "\n",
    "    fbeta = score(solution_df, submission_df, min_radius=1000, beta=2)\n",
    "    logger.info(f\"Validation Fβ-score: {fbeta:.4f}\")\n",
    "    return val_loss / len(loader.dataset), fbeta\n",
    "\n",
    "# Extract centroid (from optimized code)\n",
    "def extract_centroid(heatmap, size, offset, xy_size=(256, 256), threshold=0.3):\n",
    "    heatmap = heatmap.squeeze()\n",
    "    if heatmap.max() < threshold:\n",
    "        return torch.tensor([-1, -1], dtype=torch.float32, device=heatmap.device), torch.zeros(2, device=heatmap.device), torch.zeros(2, device=heatmap.device)\n",
    "    peak_value, peak_idx = heatmap.view(-1).topk(1)\n",
    "    if peak_value < threshold:\n",
    "        return torch.tensor([-1, -1], dtype=torch.float32, device=heatmap.device), torch.zeros(2, device=heatmap.device), torch.zeros(2, device=heatmap.device)\n",
    "    y = peak_idx // xy_size[1]\n",
    "    x = peak_idx % xy_size[1]\n",
    "    y_norm = torch.clamp(y.float() / xy_size[0], 0, 1)\n",
    "    x_norm = torch.clamp(x.float() / xy_size[1], 0, 1)\n",
    "    center = torch.tensor([y_norm, x_norm], dtype=torch.float32, device=heatmap.device)\n",
    "    pred_size = size[:, y, x].squeeze()\n",
    "    pred_offset = offset[:, y, x].squeeze()\n",
    "    center = center + pred_offset\n",
    "    return center, pred_size, pred_offset\n",
    "\n",
    "# Denormalize predictions (from optimized code)\n",
    "def denormalize_predictions(pred_center, pred_size, z, orig_shape):\n",
    "    pred_center_denorm = torch.zeros(3, dtype=torch.float32, device=pred_center.device)\n",
    "    pred_center_denorm[0] = z\n",
    "    pred_center_denorm[1] = pred_center[0] * orig_shape[0]\n",
    "    pred_center_denorm[2] = pred_center[1] * orig_shape[1]\n",
    "    pred_size_denorm = pred_size * torch.tensor([orig_shape[0], orig_shape[1]], dtype=torch.float32, device=pred_size.device)\n",
    "    return pred_center_denorm, pred_size_denorm\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "patience = 10\n",
    "trigger_times = 0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_fbetas = []\n",
    "best_model_path = \"/kaggle/working/best_model.pth\"\n",
    "\n",
    "logger.info(\"Starting training...\")\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    logger.info(f\"Starting epoch {epoch+1}/{num_epochs}\")\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, scaler)\n",
    "    val_loss, val_fbeta = validate(model, val_loader, criterion, device)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_fbetas.append(val_fbeta)\n",
    "    scheduler.step()\n",
    "\n",
    "    logger.info(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Fβ: {val_fbeta:.4f}\")\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'best_val_fbeta': best_val_fbeta,\n",
    "    }, checkpoint_path)\n",
    "\n",
    "    if val_fbeta > best_val_fbeta:\n",
    "        best_val_fbeta = val_fbeta\n",
    "        trigger_times = 0\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        logger.info(f\"Saved best model with Val Fβ: {best_val_fbeta:.4f}\")\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        logger.info(f\"No improvement in Val Fβ. Epochs without improvement: {trigger_times}/{patience}\")\n",
    "        if trigger_times >= patience:\n",
    "            logger.info(\"Early stopping triggered\")\n",
    "            model.load_state_dict(torch.load(best_model_path))\n",
    "            logger.info(f\"Loaded best model with Val Fβ: {best_val_fbeta:.4f}\")\n",
    "            break\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Prediction on test set\n",
    "def process_tomogram(tomo_id, model, test_dataset, device, index=0, total=1, confidence_threshold=0.3):\n",
    "    logger.info(f\"Processing tomogram {tomo_id} ({index}/{total})\") \n",
    "    tomo_dir = os.path.join('/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/test', tomo_id)\n",
    "    slice_files = sorted([os.path.join(tomo_dir, f) for f in os.listdir(tomo_dir) if f.endswith('.jpg')])\n",
    "    num_slices = len(slice_files)\n",
    "\n",
    "    tomo_data = next(item for item in test_dataset.data if item['tomo_id'] == tomo_id)\n",
    "    orig_shape = tomo_data['orig_shape']\n",
    "\n",
    "    all_detections = []\n",
    "    batch_size = 4 if device.startswith('cuda') else os.cpu_count() * 2\n",
    "\n",
    "    if device.startswith('cuda'):\n",
    "        gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        free_mem = gpu_mem - torch.cuda.memory_allocated(0) / 1e9\n",
    "        batch_size = max(4, min(16, int(free_mem / 2)))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_start in range(0, num_slices, batch_size):\n",
    "            batch_end = min(batch_start + batch_size, num_slices)\n",
    "            batch_paths = slice_files[batch_start:batch_end]\n",
    "            batch_slices = preprocess_batch(batch_paths).to(device)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred_heatmaps, pred_sizes, pred_offsets = model(batch_slices)\n",
    "\n",
    "            for i, (heatmap, size, offset) in enumerate(zip(pred_heatmaps, pred_sizes, pred_offsets)):\n",
    "                confidence = heatmap.max().item()\n",
    "                if confidence >= confidence_threshold:\n",
    "                    pred_center_norm, pred_size_norm, _ = extract_centroid(heatmap, size, offset, threshold=confidence_threshold)\n",
    "                    z = batch_start + i\n",
    "                    pred_center, pred_size = denormalize_predictions(pred_center_norm, pred_size_norm, z, orig_shape[:2])\n",
    "                    all_detections.append({\n",
    "                        'z': z,\n",
    "                        'y': pred_center[1].item(),\n",
    "                        'x': pred_center[2].item(),\n",
    "                        'confidence': confidence,\n",
    "                        'width': pred_size[1].item(),\n",
    "                        'height': pred_size[0].item()\n",
    "                    })\n",
    "\n",
    "    logger.info(f\"Processing tomogram {tomo_id}: Applying 3D NMS with distance_threshold=0.1\")  # CHANGE in process_tomogram (line ~764): Added logging to track NMS application\n",
    "    final_detections = perform_3d_nms(all_detections, distance_threshold=0.1)  # CHANGE in process_tomogram (line ~766): Fixed TypeError by changing nms_threshold to distance_threshold\n",
    "    logger.info(f\"Tomogram {tomo_id}: {len(final_detections)} detections after NMS\")  # CHANGE in process_tomogram (line ~767): Added logging to report NMS results\n",
    "    if not final_detections:\n",
    "        logger.warning(f\"Tomogram {tomo_id}: No detections after NMS, returning default (-1, -1, -1)\")  # CHANGE in process_tomogram (line ~768): Added logging for default case\n",
    "        return {'tomo_id': tomo_id, 'Motor axis 0': -1, 'Motor axis 1': -1, 'Motor axis 2': -1}\n",
    "\n",
    "    final_detections.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "    best_detection = final_detections[0]\n",
    "\n",
    "    return {\n",
    "        'tomo_id': tomo_id,\n",
    "        'Motor axis 0': round(best_detection['z']),  # CHANGE in process_tomogram (line ~773): Kept original author's rounding for consistency with submission format\n",
    "        'Motor axis 1': round(best_detection['y']),  # CHANGE in process_tomogram (line ~774): Kept original author's rounding for consistency with submission format\n",
    "        'Motor axis 2': round(best_detection['x'])   # CHANGE in process_tomogram (line ~775): Kept original author's rounding for consistency with submission format\n",
    "    }\n",
    "\n",
    "def preprocess_batch(slice_paths, new_size=(256, 256)):\n",
    "    images = []\n",
    "    for path in slice_paths:\n",
    "        img = Image.open(path).convert('L')\n",
    "        img = T.functional.resize(img, new_size)\n",
    "        img = T.functional.to_tensor(img)\n",
    "        img = (img - img.mean()) / (img.std() + 1e-8)\n",
    "        images.append(img)\n",
    "    return torch.stack(images)\n",
    "\n",
    "def perform_3d_nms(detections, distance_threshold=0.1): \n",
    "    if not detections:\n",
    "        return []\n",
    "    detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)\n",
    "    final_detections = []\n",
    "    def distance_3d(d1, d2):\n",
    "        return np.sqrt((d1['z'] - d2['z'])**2 + (d1['y'] - d2['y'])**2 + (d1['x'] - d2['x'])**2)\n",
    "    trust_region = 4\n",
    "    threshold = trust_region * distance_threshold\n",
    "    while detections:\n",
    "        best_detection = detections.pop(0)\n",
    "        final_detections.append(best_detection)\n",
    "        detections = [d for d in detections if distance_3d(d, best_detection) > threshold]\n",
    "    return final_detections\n",
    "\n",
    "\n",
    "def generate_submission(test_dataset, model, device):\n",
    "    logger.info(\"Starting generate_submission\")\n",
    "    total_tomos = len(test_dataset.tomo_ids)\n",
    "    model.to(device)\n",
    "    if device.startswith('cuda'):\n",
    "        try:\n",
    "            model.half()\n",
    "            logger.info(\"Using FP16 for inference\")\n",
    "        except:\n",
    "            logger.info(\"FP16 not supported\")\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "        args_list = [(tomo_id, model, test_dataset, device, i + 1, total_tomos) \n",
    "                     for i, tomo_id in enumerate(test_dataset.tomo_ids)]\n",
    "        results = list(executor.map(process_tomogram_wrapper, args_list))\n",
    "    submission_df = pd.DataFrame(results, columns=['tomo_id', 'Motor axis 0', 'Motor axis 1', 'Motor axis 2'])\n",
    "    submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "    motors_found = sum(1 for r in results if r['Motor axis 0'] != -1)\n",
    "    logger.info(f\"Submission saved. Motors detected: {motors_found}/{total_tomos}\")\n",
    "    return submission_df\n",
    "\n",
    "def process_tomogram_wrapper(args):\n",
    "    tomo_id, model, test_dataset, device, index, total = args  \n",
    "    return process_tomogram(tomo_id, model, test_dataset, device, index, total)\n",
    "\n",
    "# Run the pipeline\n",
    "start_time = time.time()\n",
    "logger.info(\"Starting training...\")\n",
    "model.train()\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, scaler)\n",
    "    val_loss, val_fbeta = validate(model, val_loader, criterion, device)\n",
    "    logger.info(f\"Epoch {epoch+1}/{num_epochs} completed. Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Fβ: {val_fbeta:.4f}\")\n",
    "logger.info(\"Generating test predictions...\")\n",
    "submission_df = generate_submission(test_dataset, model, device)\n",
    "logger.info(f\"Total execution time: {(time.time() - start_time)/60:.2f} minutes\")\n",
    "logger.info(\"Pipeline completed\")  # CHANGE in training loop (line ~680): Added logging to confirm pipeline completion\n",
    "sys.stdout.flush()  # CHANGE in training loop (line ~681): Added flush to ensure logs are written immediately\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b377a698",
   "metadata": {
    "papermill": {
     "duration": 0.279207,
     "end_time": "2025-05-26T09:02:05.946423",
     "exception": false,
     "start_time": "2025-05-26T09:02:05.667216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11294684,
     "sourceId": 91249,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1334.77414,
   "end_time": "2025-05-26T09:02:09.392106",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-26T08:39:54.617966",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
