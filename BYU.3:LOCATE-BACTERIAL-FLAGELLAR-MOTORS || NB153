{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":91249,"databundleVersionId":11294684,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom pathlib import Path\nimport os\nfrom PIL import Image\nimport torchvision.transforms as T\nfrom tqdm import tqdm\nimport logging\nimport sys\nfrom sklearn.model_selection import train_test_split\nimport torch.optim as optim\nfrom concurrent.futures import ThreadPoolExecutor\nimport time\nimport gc\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.metrics import fbeta_score\nimport warnings # to suppress FutureWarning cuda warnings \nfrom torch import amp\n\n# Set random seed for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# Configure logging\nlogger = logging.getLogger('')\nlogger.setLevel(logging.INFO)\nlogger.handlers = []\nfile_handler = logging.FileHandler(\"/kaggle/working/training.log\", mode='w')\nfile_handler.setLevel(logging.INFO)\nfile_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\nfile_handler.flush = lambda: file_handler.stream.flush()  # Force flush\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler(sys.stdout)\nconsole_handler.setLevel(logging.ERROR)\nconsole_handler.setFormatter(logging.Formatter('%(levelname)s - %(message)s'))\nlogger.addHandler(console_handler)\nlogger.info(\"Logging initialized to /kaggle/working/training.log\")\n\n\n# Redirect print to logger\n# def redirect_print_to_log(*args, **kwargs):\n#     logger.info(\" \".join(map(str, args)))\n# sys.stdout.write = redirect_print_to_log\n\n# MultiHeadSelfAttention\nclass MultiHeadSelfAttention(nn.Module):\n    def __init__(self, in_channels, num_heads=8):\n        super(MultiHeadSelfAttention, self).__init__()\n        assert in_channels % num_heads == 0, \"in_channels must be divisible by num_heads\"\n        self.in_channels = in_channels\n        self.num_heads = num_heads\n        self.head_dim = in_channels // num_heads\n        self.query = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n        self.key = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n        self.value = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n        self.out_proj = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n        self.gamma = nn.Parameter(torch.zeros(1))\n        self.softmax = nn.Softmax(dim=-1)\n\n    def forward(self, x):\n        batch, channels, height, width = x.size()\n        n_pixels = height * width\n        proj_query = self.query(x).view(batch, self.num_heads, self.head_dim, n_pixels).permute(0, 1, 3, 2)\n        proj_key = self.key(x).view(batch, self.num_heads, self.head_dim, n_pixels)\n        proj_value = self.value(x).view(batch, self.num_heads, self.head_dim, n_pixels).permute(0, 1, 3, 2)\n        energy = torch.matmul(proj_query, proj_key) / (self.head_dim ** 0.5)\n        energy = torch.clamp(energy, min=-10, max=10)\n        attention = self.softmax(energy)\n        out = torch.matmul(attention, proj_value)\n        out = out.permute(0, 1, 3, 2).contiguous().view(batch, self.in_channels, height, width)\n        out = self.out_proj(out)\n        return self.gamma * out + x\n\n# EnhancedCABM2D\nclass EnhancedCABM2D(nn.Module):\n    def __init__(self, in_channels, reduction=16):\n        super(EnhancedCABM2D, self).__init__()\n        self.global_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc1 = nn.Conv2d(in_channels, in_channels // reduction, kernel_size=1)\n        self.fc2 = nn.Conv2d(in_channels // reduction, in_channels, kernel_size=1)\n        self.sigmoid = nn.Sigmoid()\n        self.conv_spatial1 = nn.Conv2d(in_channels, 1, kernel_size=7, padding=3, dilation=1, bias=False)\n        self.conv_spatial2 = nn.Conv2d(in_channels, 1, kernel_size=7, padding=9, dilation=3, bias=False)\n        self.conv_refine = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n        self.bn = nn.BatchNorm2d(in_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.self_attention = MultiHeadSelfAttention(in_channels, num_heads=8)\n\n    def forward(self, x):\n        channel_avg = self.global_pool(x)\n        channel_att = self.fc1(channel_avg)\n        channel_att = self.relu(channel_att)\n        channel_att = self.fc2(channel_att)\n        channel_att = self.sigmoid(channel_att)\n        x_channel = x * channel_att\n        spatial_att1 = self.conv_spatial1(x_channel)\n        spatial_att2 = self.conv_spatial2(x_channel)\n        spatial_att = self.sigmoid(spatial_att1 + spatial_att2)\n        x_spatial = x_channel * spatial_att\n        x_self_att = self.self_attention(x_spatial)\n        x_refined = self.conv_refine(x_self_att)\n        x_refined = self.bn(x_refined)\n        x_refined = self.relu(x_refined)\n        return x + x_refined\n\n# OptimizedCenterNet2D\nclass OptimizedCenterNet2D(nn.Module):\n    def __init__(self, in_channels=1, out_channels=1):\n        super(OptimizedCenterNet2D, self).__init__()\n        self.enc1 = nn.Sequential(\n            nn.Conv2d(in_channels, 32, kernel_size=3, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.Dropout(0.3)\n        )\n        self.enc2 = nn.Sequential(\n            nn.Conv2d(32, 64, kernel_size=3, padding=1, stride=2),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.Dropout(0.3)\n        )\n        self.enc3 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=3, padding=1, stride=2),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.Dropout(0.3)\n        )\n        self.enc4 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=3, padding=1, stride=2),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.Dropout(0.3)\n        )\n        self.attention = EnhancedCABM2D(in_channels=256)\n        self.dec4 = nn.Sequential(\n            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU()\n        )\n        self.dec3 = nn.Sequential(\n            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU()\n        )\n        self.dec2 = nn.Sequential(\n            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU()\n        )\n        self.heatmap_head = nn.Sequential(\n            nn.Conv2d(32, out_channels, kernel_size=1),\n            nn.Sigmoid()\n        )\n        self.size_head = nn.Conv2d(32, 2, kernel_size=1)\n        self.offset_head = nn.Conv2d(32, 2, kernel_size=1)\n\n    def forward(self, x):\n        e1 = self.enc1(x)\n        e2 = self.enc2(e1)\n        e3 = self.enc3(e2)\n        e4 = self.enc4(e3)\n        e4_att = self.attention(e4)\n        d4 = self.dec4(e4_att) + e3\n        d3 = self.dec3(d4) + e2\n        d2 = self.dec2(d3) + e1\n        heatmap = self.heatmap_head(d2)\n        size = self.size_head(d2)\n        offset = self.offset_head(d2)\n        return heatmap, size, offset\n\n# CenterNetLoss\nclass CenterNetLoss(nn.Module):\n    def __init__(self, gamma=2.0, size_weight=1.0, offset_weight=0.1):\n        super(CenterNetLoss, self).__init__()\n        self.gamma = gamma\n        self.size_weight = size_weight\n        self.offset_weight = offset_weight\n\n    def gaussian_focal_loss(self, pred_heatmap, target_heatmap):\n        pos_loss = -target_heatmap * (1 - pred_heatmap) ** self.gamma * torch.log(pred_heatmap + 1e-6)\n        neg_loss = -(1 - target_heatmap) * pred_heatmap ** self.gamma * torch.log(1 - pred_heatmap + 1e-6)\n        loss = (pos_loss + neg_loss).sum() / pred_heatmap.size(0)\n        return loss\n\n    def forward(self, pred_heatmap, pred_size, pred_offset, target_heatmap, target_size, target_offset):\n        gfl = self.gaussian_focal_loss(pred_heatmap, target_heatmap)\n        batch_size = pred_heatmap.size(0)\n        pred_size_at_centers = torch.zeros(batch_size, 2, device=pred_heatmap.device)\n        pred_offset_at_centers = torch.zeros(batch_size, 2, device=pred_heatmap.device)\n        for i in range(batch_size):\n            heatmap = pred_heatmap[i].squeeze()\n            peak_idx = heatmap.view(-1).argmax()\n            y = peak_idx // 256\n            x = peak_idx % 256\n            pred_size_at_centers[i] = pred_size[i, :, y, x]\n            pred_offset_at_centers[i] = pred_offset[i, :, y, x]\n        size_loss = F.mse_loss(pred_size_at_centers, target_size, reduction='mean') * self.size_weight\n        offset_loss = F.mse_loss(pred_offset_at_centers, target_offset, reduction='mean') * self.offset_weight\n        return gfl + size_loss + offset_loss\n\n\n# FlagellarDataset - storage containing image tensors, heatmaps, sizes, offfsets and metadata\nclass FlagellarDataset(Dataset):\n    def __init__(self, tomo_ids, csv_file=None, root_dir=None, new_size=(256, 256), trust_region=4, is_test=False):\n        self.tomo_ids = tomo_ids\n        self.csv_file = csv_file\n        self.root_dir = Path(root_dir)\n        self.new_size = new_size\n        self.trust_region = trust_region\n        self.is_test = is_test\n        self.data = []\n        self.spatial_augment = T.Compose([\n            T.RandomHorizontalFlip(p=0.5),\n            T.RandomRotation(degrees=5),\n            T.RandomAffine(degrees=0, scale=(0.95, 1.05))\n        ])\n        self.image_augment = T.Compose([\n            T.RandomApply([T.ColorJitter(brightness=0.1, contrast=0.1)], p=0.2)\n        ])\n        logger.info(f\"Initializing {'test' if is_test else 'train/val'} dataset with {len(tomo_ids)} tomograms, is_test={is_test}\")\n\n        if csv_file and os.path.exists(csv_file) and not is_test:\n            labels = pd.read_csv(csv_file)\n            self.motors_map = labels.groupby('tomo_id').apply(\n                lambda g: np.array(g[['Motor axis 0', 'Motor axis 1', 'Motor axis 2']].values[0], dtype=np.float32),\n                include_groups=False\n            ).to_dict()\n            self.size_map = labels.groupby('tomo_id').agg({\n                'Array shape (axis 1)': 'first',\n                'Array shape (axis 2)': 'first',\n                'Array shape (axis 0)': 'first',\n                'Voxel spacing': 'first'\n            }).to_dict('index')\n            logger.info(f\"Loaded labels for {len(self.motors_map)} tomograms from {csv_file}\")\n\n            skipped_tomograms = []\n            for tomo_id in tqdm(self.tomo_ids, desc=\"Loading training data\"):\n                if tomo_id not in self.motors_map:\n                    logger.warning(f\"Tomogram {tomo_id} not in labels, skipping. Available tomo_ids: {sorted(list(self.motors_map.keys()))[:10]}...\")\n                    skipped_tomograms.append(tomo_id)\n                    continue\n                \n                tomo_dir = self.root_dir.joinpath(tomo_id)\n                if not tomo_dir.exists():\n                    logger.warning(f\"Tomogram {tomo_id} directory {tomo_dir} does not exist, skipping\")\n                    skipped_tomograms.append(tomo_id)\n                    continue\n\n                motor = self.motors_map[tomo_id]\n                files = sorted(tomo_dir.glob('*.jpg'))\n                num_slices = len(files)\n                if num_slices == 0:\n                    logger.warning(f\"Tomogram {tomo_id} has no slices in {tomo_dir}, skipping\")\n                    skipped_tomograms.append(tomo_id)\n                    continue\n\n                if np.all(motor == -1):\n                    center_z = num_slices // 2\n                    z_start = max(0, center_z - self.trust_region)\n                    z_end = min(num_slices, center_z + self.trust_region + 1)\n                    slices_added = 0\n                \n                    for z in range(z_start, z_end):\n                        slice_path = files[z] if z < len(files) else None\n                        if not slice_path or not slice_path.exists():\n                            logger.debug(f\"Tomogram {tomo_id}, slice {z} not found at {slice_path or tomo_dir}, skipping slice\")\n                            continue\n                \n                        img = Image.open(slice_path).convert('L')\n                        img = T.functional.resize(img, self.new_size)\n                        img = T.functional.to_tensor(img)\n                        img = (img - img.mean()) / (img.std() + 1e-8)\n                \n                        motor_norm = torch.tensor([-1, -1], dtype=torch.float32)\n                        heatmap = torch.zeros(self.new_size)\n                        size_target = torch.zeros(2, dtype=torch.float32)\n                        offset_target = torch.zeros(2, dtype=torch.float32)\n                \n                        if not self.is_test:\n                            img_aug = self.image_augment(img)\n                            stacked = torch.stack([img_aug[0], heatmap], dim=0)\n                            stacked_aug = self.spatial_augment(stacked)\n                            img = stacked_aug[0].unsqueeze(0)\n                            heatmap = stacked_aug[1]\n                \n                        self.data.append({\n                            'tomo_id': tomo_id,\n                            'slice': img,\n                            'heatmap': heatmap,\n                            'size': size_target,\n                            'offset': offset_target,\n                            'center': motor_norm,\n                            'z': z,\n                            'orig_shape': torch.tensor([self.size_map[tomo_id]['Array shape (axis 1)'],\n                                                      self.size_map[tomo_id]['Array shape (axis 2)'],\n                                                      num_slices], dtype=torch.float32),\n                            'voxel_spacing': self.size_map[tomo_id]['Voxel spacing'],\n                            'motor': torch.tensor(motor, dtype=torch.float32)\n                        })\n                        slices_added += 1\n                \n                    if slices_added == 0:\n                        logger.warning(f\"Tomogram {tomo_id} has no valid slices in trust region (z={z_start} to {z_end-1}), skipping\")\n                        skipped_tomograms.append(tomo_id)\n                    else:\n                        logger.debug(f\"Processed tomogram {tomo_id}: Added {slices_added} slices (z={z_start} to {z_end-1})\")\n                    continue\n\n                center_z = int(motor[0])\n                z_start = max(0, center_z - self.trust_region)\n                z_end = min(num_slices, center_z + self.trust_region + 1)\n                slices_added = 0\n\n                for z in range(z_start, z_end):\n                    slice_path = files[z] if z < len(files) else None\n                    if not slice_path or not slice_path.exists():\n                        logger.debug(f\"Tomogram {tomo_id}, slice {z} not found at {slice_path or tomo_dir}, skipping slice\")\n                        continue\n\n                    img = Image.open(slice_path).convert('L')\n                    img = T.functional.resize(img, new_size)\n                    img = T.functional.to_tensor(img)\n                    img = (img - img.mean()) / (img.std() + 1e-8)\n\n                    motor_norm = torch.tensor([\n                        motor[1] / self.size_map[tomo_id]['Array shape (axis 1)'],\n                        motor[2] / self.size_map[tomo_id]['Array shape (axis 2)']\n                    ], dtype=torch.float32)\n\n                    heatmap = self.generate_gaussian_heatmap(motor_norm, self.new_size)\n                    voxel_spacing = self.size_map[tomo_id]['Voxel spacing']\n                    orig_height = self.size_map[tomo_id]['Array shape (axis 1)']\n                    orig_width = self.size_map[tomo_id]['Array shape (axis 2)']\n                    target_size_pixels_y = 1000.0 / voxel_spacing\n                    target_size_pixels_x = 1000.0 / voxel_spacing\n                    size_target = torch.tensor([\n                        target_size_pixels_y / orig_height,\n                        target_size_pixels_x / orig_width\n                    ], dtype=torch.float32)\n                    offset_target = torch.zeros(2, dtype=torch.float32)\n\n                    if not self.is_test:\n                        img_aug = self.image_augment(img)\n                        stacked = torch.stack([img_aug[0], heatmap], dim=0)\n                        stacked_aug = self.spatial_augment(stacked)\n                        img = stacked_aug[0].unsqueeze(0)\n                        heatmap = stacked_aug[1]\n                        peak_idx = heatmap.view(-1).argmax()\n                        y_new = peak_idx // self.new_size[1]\n                        x_new = peak_idx % self.new_size[1]\n                        motor_norm = torch.tensor([y_new / self.new_size[0], x_new / self.new_size[1]], dtype=torch.float32)\n\n                    self.data.append({\n                        'tomo_id': tomo_id,\n                        'slice': img,\n                        'heatmap': heatmap,\n                        'size': size_target,\n                        'offset': offset_target,\n                        'center': motor_norm,\n                        'z': z,\n                        'orig_shape': torch.tensor([self.size_map[tomo_id]['Array shape (axis 1)'],\n                                                  self.size_map[tomo_id]['Array shape (axis 2)'],\n                                                  num_slices], dtype=torch.float32),\n                        'voxel_spacing': self.size_map[tomo_id]['Voxel spacing'],\n                        'motor': torch.tensor(motor, dtype=torch.float32)\n                    })\n                    slices_added += 1\n\n                if slices_added == 0:\n                    logger.warning(f\"Tomogram {tomo_id} has no valid slices in trust region (z={z_start} to {z_end-1}), skipping\")\n                    skipped_tomograms.append(tomo_id)\n                else:\n                    logger.debug(f\"Processed tomogram {tomo_id}: Added {slices_added} slices (z={z_start} to {z_end-1})\")\n\n            logger.info(f\"Training dataset initialized: {len(self.data)} slices from {len(tomo_ids) - len(skipped_tomograms)} tomograms, {len(skipped_tomograms)} tomograms skipped\")\n            if skipped_tomograms:\n                logger.warning(f\"Skipped tomograms: {sorted(skipped_tomograms)}\")\n        else:\n            for tomo_id in tqdm(self.tomo_ids, desc=\"Loading test data\"):\n                files = sorted(self.root_dir.joinpath(tomo_id).glob('*.jpg'))\n                num_slices = len(files)\n                if num_slices == 0:\n                    logger.warning(f\"Test tomogram {tomo_id} has no slices in {self.root_dir.joinpath(tomo_id)}, skipping\")\n                    continue\n                orig_shape = torch.tensor([Image.open(files[0]).size[1], Image.open(files[0]).size[0], num_slices], dtype=torch.float32)\n                for z, file in enumerate(files):\n                    self.data.append({\n                        'tomo_id': tomo_id,\n                        'slice_path': str(file),\n                        'z': z,\n                        'orig_shape': orig_shape\n                    })\n                logger.debug(f\"Test tomogram {tomo_id}: Loaded {num_slices} slices\")\n            logger.info(f\"Test dataset initialized: {len(self.data)} slices from {len(tomo_ids)} tomograms\")\n\n    def generate_gaussian_heatmap(self, center, xy_size, sigma=4.0):\n        heatmap = torch.zeros(xy_size)\n        yc, xc = center\n        yc = yc * xy_size[0]\n        xc = xc * xy_size[1]\n        y_coords, x_coords = torch.meshgrid(\n            torch.arange(xy_size[0], dtype=torch.float32),\n            torch.arange(xy_size[1], dtype=torch.float32),\n            indexing='ij'\n        )\n        dist = ((y_coords - yc) ** 2 + (x_coords - xc) ** 2) / (2.0 * sigma ** 2)\n        heatmap = torch.exp(-dist)\n        return heatmap\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        item = self.data[idx]\n        if self.is_test:\n            return {\n                'tomo_id': item['tomo_id'],\n                'slice_path': item['slice_path'],\n                'z': item['z'],\n                'orig_shape': item['orig_shape']\n            }\n        return {\n            'tomo_id': item['tomo_id'],\n            'slice': item['slice'],\n            'heatmap': item['heatmap'].unsqueeze(0),\n            'size': item['size'],\n            'offset': item['offset'],\n            'center': item['center'],\n            'z': item['z'],\n            'orig_shape': item['orig_shape'],\n            'voxel_spacing': item['voxel_spacing'],\n            'motor': item['motor']\n        }\n\ndef custom_collate_fn(batch):\n    if 'slice' in batch[0]:\n        return {\n            'tomo_id': [item['tomo_id'] for item in batch],\n            'slice': torch.stack([item['slice'] for item in batch]),\n            'heatmap': torch.stack([item['heatmap'] for item in batch]),\n            'size': torch.stack([item['size'] for item in batch]),\n            'offset': torch.stack([item['offset'] for item in batch]),\n            'center': torch.stack([item['center'] for item in batch]),\n            'z': torch.tensor([item['z'] for item in batch], dtype=torch.float32),\n            'orig_shape': torch.stack([item['orig_shape'] for item in batch]),\n            'voxel_spacing': torch.tensor([item['voxel_spacing'] for item in batch], dtype=torch.float32),\n            'motor': torch.stack([item['motor'] for item in batch])\n        }\n    else:\n        return {\n            'tomo_id': [item['tomo_id'] for item in batch],\n            'slice_path': [item['slice_path'] for item in batch],\n            'z': torch.tensor([item['z'] for item in batch], dtype=torch.float32),\n            'orig_shape': torch.stack([item['orig_shape'] for item in batch])\n        }\n\n# Extract centroid (from optimized code)\ndef extract_centroid(heatmap, size, offset, xy_size=(256, 256), threshold=0.3):\n    heatmap = heatmap.squeeze()\n    if heatmap.max() < threshold:\n        return torch.tensor([-1, -1], dtype=torch.float32, device=heatmap.device), torch.zeros(2, device=heatmap.device), torch.zeros(2, device=heatmap.device)\n    peak_value, peak_idx = heatmap.view(-1).topk(1)\n    if peak_value < threshold:\n        return torch.tensor([-1, -1], dtype=torch.float32, device=heatmap.device), torch.zeros(2, device=heatmap.device), torch.zeros(2, device=heatmap.device)\n    y = peak_idx // xy_size[1]\n    x = peak_idx % xy_size[1]\n    y_norm = torch.clamp(y.float() / xy_size[0], 0, 1)\n    x_norm = torch.clamp(x.float() / xy_size[1], 0, 1)\n    center = torch.tensor([y_norm, x_norm], dtype=torch.float32, device=heatmap.device)\n    pred_size = size[:, y, x].squeeze()\n    pred_offset = offset[:, y, x].squeeze()\n    center = center + pred_offset\n    return center, pred_size, pred_offset\n\n# Denormalize predictions (from optimized code)\ndef denormalize_predictions(pred_center, pred_size, z, orig_shape):\n    pred_center_denorm = torch.zeros(3, dtype=torch.float32, device=pred_center.device)\n    pred_center_denorm[0] = z\n    pred_center_denorm[1] = pred_center[0] * orig_shape[0]\n    pred_center_denorm[2] = pred_center[1] * orig_shape[1]\n    pred_size_denorm = pred_size * torch.tensor([orig_shape[0], orig_shape[1]], dtype=torch.float32, device=pred_size.device)\n    return pred_center_denorm, pred_size_denorm\n\n# Train/validation/test split \ndef identify_motor_tomograms(labels_df):\n    motor_tomograms = []\n    for tomo_id in labels_df[\"tomo_id\"].unique():\n        tomo_labels = labels_df[labels_df[\"tomo_id\"] == tomo_id].iloc[0]\n        if tomo_labels[\"Number of motors\"] > 0 and tomo_labels[\"Motor axis 0\"] != -1:\n            motor_tomograms.append(tomo_id)\n    logger.info(f\"Found {len(motor_tomograms)} tomograms with motors\")\n    logger.debug(f\"Motor tomogram IDs: {sorted(motor_tomograms)}\")\n    return motor_tomograms\n\nlabels_df = pd.read_csv(\"/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/train_labels.csv\")\ntomo_ids = sorted(labels_df[\"tomo_id\"].unique())\ntrain_ids, val_ids = train_test_split(tomo_ids, test_size=0.2, random_state=42)\ntest_ids = [\"tomo_003acc\", \"tomo_00e047\", \"tomo_01a877\"]\nlogger.info(f\"Total tomograms: {len(tomo_ids)}, Training tomograms: {len(train_ids)}, Validation tomograms: {len(val_ids)}, Test tomograms: {len(test_ids)}\")\nlogger.debug(f\"Training tomogram IDs: {sorted(train_ids)}\")\nlogger.debug(f\"Validation tomogram IDs: {sorted(val_ids)}\")\nlogger.debug(f\"Test tomogram IDs: {sorted(test_ids)}\")\n\n# Dataset creation for train val and test\ntrain_dataset = FlagellarDataset(\n    tomo_ids=train_ids,\n    csv_file='/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/train_labels.csv',\n    root_dir='/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/train',\n    new_size=(256, 256),\n    trust_region=4\n)\nval_dataset = FlagellarDataset(\n    tomo_ids=val_ids,\n    csv_file='/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/train_labels.csv',\n    root_dir='/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/train',\n    new_size=(256, 256),\n    trust_region=4\n)\ntest_dataset = FlagellarDataset(\n    tomo_ids=test_ids,\n    root_dir='/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/test',\n    new_size=(256, 256),\n    trust_region=4,\n    is_test=True\n)\n\n# DataLoaders\ntrain_loader = DataLoader(\n    train_dataset, batch_size=8, shuffle=True,\n    collate_fn=custom_collate_fn, num_workers=0, pin_memory=True\n)\nval_loader = DataLoader(\n    val_dataset, batch_size=8, shuffle=False,\n    collate_fn=custom_collate_fn, num_workers=0, pin_memory=True\n)\n\n# Model, loss, optimizer\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nlogger.info(f\"Using device: {device}\")\nmodel = OptimizedCenterNet2D().to(device)\ncriterion = CenterNetLoss()\noptimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=5e-4) #was 1e-4\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)\n#scaler = torch.cuda.amp.GradScaler()\nscaler = amp.GradScaler('cuda')  # Was torch.cuda.amp.GradScaler()\n\n# Checkpoint loading\nstart_epoch = 0\nbest_val_fbeta = 0.0\ncheckpoint_path = \"/kaggle/working/checkpoint.pth\"\nif os.path.exists(checkpoint_path):\n    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n    start_epoch = checkpoint['epoch'] + 1\n    best_val_fbeta = checkpoint['best_val_fbeta']\n    logger.info(f\"Resumed from epoch {start_epoch}, best validation F2: {best_val_fbeta}\")\nelse:\n    logger.info(\"No checkpoint found, starting from scratch.\")\n\ndef calculate_fbeta_score(pred_centers, true_centers, voxel_spacings, threshold_angstroms=1000, beta=2.0):\n    TP, TN, FP, FN = 0, 0, 0, 0\n    for pred_center, true_center, voxel_spacing in zip(pred_centers, true_centers, voxel_spacings):\n        voxel_spacing = voxel_spacing.item()\n        pred_array = pred_center.detach().cpu().numpy()\n        true_array = true_center.detach().cpu().numpy()\n\n        if np.all(true_array == -1):\n            if np.all(pred_array == -1):\n                TN += 1\n            else:\n                FP += 1\n            continue\n        if np.all(pred_array == -1):\n            FN += 1\n            continue\n\n        distance = np.linalg.norm((true_array - pred_array) * voxel_spacing)\n        if distance <= threshold_angstroms:\n            TP += 1\n        else:\n            FN += 1\n\n    if TP + FP + FN == 0:\n        fbeta = 0.0\n    else:\n        beta2 = beta ** 2\n        fbeta = (1 + beta2) * TP / ((1 + beta2) * TP + beta2 * FN + FP)\n    return fbeta, TP, TN, FP, FN\n\ndef plot_slices(model, example, device):\n    model.eval()\n    with torch.no_grad():\n        slice_data = example['slice'].unsqueeze(0).to(device)\n        heatmap_true = example['heatmap'].unsqueeze(0)\n        size_true = example['size']\n        offset_true = example['offset']\n        center = example['center']\n        orig_shape = example['orig_shape'].to(device)\n        tomo_id = example['tomo_id']\n        z = example['z']\n\n        heatmap_pred, size_pred, offset_pred = model(slice_data)\n        heatmap_pred, size_pred, offset_pred = heatmap_pred[0], size_pred[0], offset_pred[0]\n        heatmap_true = heatmap_true[0]\n\n        pred_center_norm, pred_size_norm, pred_offset_norm = extract_centroid(heatmap_pred, size_pred, offset_pred, threshold=0.3)\n        pred_center, pred_size = denormalize_predictions(pred_center_norm, pred_size_norm, z, orig_shape[:2])\n        center_denorm, _ = denormalize_predictions(center, size_true, z, orig_shape[:2]) if torch.all(center >= 0) else (torch.tensor([-1, -1, -1], device=device), torch.zeros(2, device=device))\n\n        slice_data = slice_data[0, 0].cpu().numpy()\n        heatmap_pred_slice = heatmap_pred[0].cpu().numpy()\n        heatmap_true_slice = heatmap_true[0].cpu().numpy()\n\n        distance = np.linalg.norm(center_denorm.cpu().numpy() - pred_center.cpu().numpy()) if torch.all(center >= 0) else float('inf')\n        distance_text = f\"Distance: {distance:.2f}\" if distance != float('inf') else \"No GT Motor\"\n\n        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n        ax = axes[0]\n        ax.imshow(slice_data, cmap='gray')\n        ax.set_title(f\"Tomo: {tomo_id}\\nZ: {z}\\n{distance_text}\")\n        ax.axis('off')\n\n        scale_y = orig_shape[0].item() / 256\n        scale_x = orig_shape[1].item() / 256\n\n        if torch.all(center >= 0):\n            true_y_display = center_denorm[1].item() / scale_y\n            true_x_display = center_denorm[2].item() / scale_x\n            ax.plot(true_x_display, true_y_display, 'go', label='GT Center')\n            rect_gt = patches.Rectangle(\n                (max(0, true_x_display - size_true[1].item() * scale_x / 2), max(0, true_y_display - size_true[0].item() * scale_y / 2)),\n                size_true[1].item() * scale_x, size_true[0].item() * scale_y, linewidth=2, edgecolor='g', facecolor='none', label='GT Box'\n            )\n            ax.add_patch(rect_gt)\n\n        if not torch.all(pred_center == -1):\n            pred_y_display = pred_center[1].item() / scale_y\n            pred_x_display = pred_center[2].item() / scale_x\n            ax.plot(pred_x_display, pred_y_display, 'ro', label='Pred Center')\n            rect_pred = patches.Rectangle(\n                (max(0, pred_x_display - pred_size[1].item() / 2), max(0, pred_y_display - pred_size[0].item() / 2)),\n                pred_size[1].item(), pred_size[0].item(), linewidth=2, edgecolor='r', facecolor='none', label='Pred Box'\n            )\n            ax.add_patch(rect_pred)\n\n        ax.legend()\n\n        axes[1].imshow(heatmap_pred_slice, cmap='hot', vmin=0, vmax=1)\n        axes[1].set_title(\"Predicted Heatmap\")\n        axes[1].axis('off')\n\n        axes[2].imshow(heatmap_true_slice, cmap='hot', vmin=0, vmax=1)\n        axes[2].set_title(\"Ground Truth Heatmap\")\n        axes[2].axis('off')\n\n        plt.tight_layout()\n        plt.show()\n\n\n# Fβ-score calculation\ndef score(solution, submission, min_radius=1000, beta=2.0):\n    solution = solution.sort_values('tomo_id').reset_index(drop=True)\n    submission = submission.sort_values('tomo_id').reset_index(drop=True)\n    if not solution['tomo_id'].eq(submission['tomo_id']).all():\n        raise ValueError('Submitted tomo_id values do not match')\n    submission['Has motor'] = 1\n    select = (submission[['Motor axis 0', 'Motor axis 1', 'Motor axis 2']] == -1).any(axis='columns')\n    submission.loc[select, 'Has motor'] = 0\n    coordinate_cols = ['Motor axis 0', 'Motor axis 1', 'Motor axis 2']\n    label_tensor = solution[coordinate_cols].values.reshape(len(solution), -1, len(coordinate_cols))\n    predicted_tensor = submission[coordinate_cols].values.reshape(len(submission), -1, len(coordinate_cols))\n    solution['distance'] = np.linalg.norm(label_tensor - predicted_tensor, axis=2).min(axis=1)\n    solution['thresholds'] = solution['Voxel spacing'].apply(lambda x: min_radius / x)\n    solution['predictions'] = submission['Has motor'].values\n    solution.loc[(solution['distance'] > solution['thresholds']) & (solution['Has motor'] == 1) & (submission['Has motor'] == 1), 'predictions'] = 0\n    return fbeta_score(solution['Has motor'].values, solution['predictions'].values, beta=beta)\n\ndef train_epoch(model, loader, criterion, optimizer, scaler, device, accum_steps=2, max_grad_norm=1.0):\n    model.train()\n    train_loss = 0.0\n    train_preds, train_trues, train_voxel_spacings = [], [], []\n    tomogram_counts = {}\n    processed_tomo_ids = set()\n    example_to_plot = None  # CHANGE: Store example for visualization\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", category=FutureWarning)\n        for i, batch in enumerate(tqdm(loader, desc=\"Training\", file=sys.stdout)):\n            slices = batch['slice'].to(device, non_blocking=True)\n            heatmaps = batch['heatmap'].to(device, non_blocking=True)\n            sizes = batch['size'].to(device, non_blocking=True)\n            offsets = batch['offset'].to(device, non_blocking=True)\n            centers = batch['center'].to(device, non_blocking=True)\n            orig_shapes = batch['orig_shape'].to(device, non_blocking=True)\n            voxel_spacings = batch['voxel_spacing'].to(device, non_blocking=True)\n            motors = batch['motor'].to(device, non_blocking=True)\n            zs = batch['z'].to(device, non_blocking=True)\n            tomo_ids = batch['tomo_id']\n\n            batch_tomo_ids = sorted(set(tomo_ids))\n            processed_tomo_ids.update(batch_tomo_ids)\n            for tomo_id in tomo_ids:\n                tomogram_counts[tomo_id] = tomogram_counts.get(tomo_id, 0) + 1\n            logger.debug(f\"Batch {i+1}/{len(loader)}, Tomograms: {batch_tomo_ids}, Batch size: {len(tomo_ids)}\")\n\n            with torch.cuda.amp.autocast():\n                pred_heatmaps, pred_sizes, pred_offsets = model(slices)\n                loss = criterion(pred_heatmaps, pred_sizes, pred_offsets, heatmaps, sizes, offsets)\n                loss = loss / accum_steps\n            scaler.scale(loss).backward()\n            train_loss += loss.item() * slices.size(0) * accum_steps\n            logger.info(f\"Batch {i+1}, Loss: {loss.item()*accum_steps:.4f}\")\n\n            # Collect predictions for F2 score\n            pred_centers_norm, pred_sizes_norm, _ = zip(*[extract_centroid(pred_heatmaps[i], pred_sizes[i], pred_offsets[i], threshold=0.3) \n                                                          for i in range(slices.size(0))])\n            pred_centers, _ = zip(*[denormalize_predictions(pred_centers_norm[i], pred_sizes_norm[i], zs[i], orig_shapes[i, :2])\n                                    for i in range(slices.size(0))])\n            train_preds.extend(pred_centers)\n            train_trues.extend(motors)\n            train_voxel_spacings.extend(voxel_spacings)\n\n            # Store first batch's first sample for visualization\n            if example_to_plot is None:\n                example_to_plot = {\n                    'slice': slices[0].cpu(),\n                    'heatmap': heatmaps[0].cpu(),\n                    'size': sizes[0].cpu(),\n                    'offset': offsets[0].cpu(),\n                    'center': centers[0].cpu(),\n                    'orig_shape': orig_shapes[0].cpu(),\n                    'tomo_id': tomo_ids[0],\n                    'z': zs[0].cpu()\n                }\n\n            if (i + 1) % accum_steps == 0:\n                scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_grad_norm)\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n\n        if (i + 1) % accum_steps != 0:\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_grad_norm)\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n\n    logger.info(f\"Training epoch: Processed {len(processed_tomo_ids)} unique tomograms, {sum(tomogram_counts.values())} slices\")\n    logger.debug(f\"Tomogram slice counts: {dict(sorted(tomogram_counts.items()))}\")\n    missing_tomograms = [tid for tid in train_ids if tid not in processed_tomo_ids]\n    if missing_tomograms:\n        logger.warning(f\"Missing {len(missing_tomograms)} tomograms in training: {sorted(missing_tomograms)}\")\n    else:\n        logger.info(\"All expected tomograms processed in training\")\n\n    train_fbeta, train_TP, train_TN, train_FP, train_FN = calculate_fbeta_score(train_preds, train_trues, train_voxel_spacings)\n    return train_loss / len(loader.dataset), train_fbeta, train_TP, train_TN, train_FP, train_FN, example_to_plot\n\n\ndef validate(model, loader, criterion, device):\n    model.eval()\n    val_loss = 0.0\n    val_preds, val_trues, val_voxel_spacings = [], [], []\n    tomo_predictions = {}\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", category=FutureWarning)\n        with torch.no_grad():\n            for batch in tqdm(loader, desc=\"Validating\"):\n                slices = batch['slice'].to(device, non_blocking=True)\n                heatmaps = batch['heatmap'].to(device, non_blocking=True)\n                sizes = batch['size'].to(device, non_blocking=True)\n                offsets = batch['offset'].to(device, non_blocking=True)\n                centers = batch['center'].to(device, non_blocking=True)\n                orig_shapes = batch['orig_shape'].to(device, non_blocking=True)\n                voxel_spacings_batch = batch['voxel_spacing'].to(device, non_blocking=True)\n                motors = batch['motor'].to(device, non_blocking=True)\n                zs = batch['z'].to(device, non_blocking=True)\n                tomo_ids = batch['tomo_id']\n\n                with torch.cuda.amp.autocast():\n                    pred_heatmaps, pred_sizes, pred_offsets = model(slices)\n                    loss = criterion(pred_heatmaps, pred_sizes, pred_offsets, heatmaps, sizes, offsets)\n                val_loss += loss.item() * slices.size(0)\n\n                pred_centers_norm, pred_sizes_norm, _ = zip(*[extract_centroid(pred_heatmaps[i], pred_sizes[i], pred_offsets[i], threshold=0.3) \n                                                              for i in range(slices.size(0))])\n                pred_centers, _ = zip(*[denormalize_predictions(pred_centers_norm[i], pred_sizes_norm[i], zs[i], orig_shapes[i, :2])\n                                        for i in range(slices.size(0))])\n                val_preds.extend(pred_centers)\n                val_trues.extend(motors)\n                val_voxel_spacings.extend(voxel_spacings_batch)\n\n                for i in range(slices.size(0)):\n                    tomo_id = tomo_ids[i]\n                    confidence = pred_heatmaps[i].max().item()\n                    pred_center_norm, _, _ = extract_centroid(pred_heatmaps[i], pred_sizes[i], pred_offsets[i], threshold=0.3)\n                    pred_center, _ = denormalize_predictions(pred_center_norm, torch.zeros(2).to(device), zs[i], orig_shapes[i, :2])\n                    if tomo_id not in tomo_predictions:\n                        tomo_predictions[tomo_id] = []\n                    tomo_predictions[tomo_id].append({\n                        'Motor axis 0': pred_center[0].item(),\n                        'Motor axis 1': pred_center[1].item(),\n                        'Motor axis 2': pred_center[2].item(),\n                        'confidence': confidence\n                    })\n\n    predictions = []\n    for tomo_id in val_ids:\n        if tomo_id in tomo_predictions and tomo_predictions[tomo_id]:\n            best_pred = max(tomo_predictions[tomo_id], key=lambda x: x['confidence'])\n            predictions.append({\n                'tomo_id': tomo_id,\n                'Motor axis 0': best_pred['Motor axis 0'],\n                'Motor axis 1': best_pred['Motor axis 1'],\n                'Motor axis 2': best_pred['Motor axis 2']\n            })\n        else:\n            predictions.append({\n                'tomo_id': tomo_id,\n                'Motor axis 0': -1,\n                'Motor axis 1': -1,\n                'Motor axis 2': -1\n            })\n\n    solution_data = []\n    for tomo_id in val_ids:\n        tomo_labels = labels_df[labels_df['tomo_id'] == tomo_id].iloc[0]\n        solution_data.append({\n            'tomo_id': tomo_id,\n            'Motor axis 0': tomo_labels['Motor axis 0'],\n            'Motor axis 1': tomo_labels['Motor axis 1'],\n            'Motor axis 2': tomo_labels['Motor axis 2'],\n            'Voxel spacing': tomo_labels['Voxel spacing'],\n            'Has motor': 1 if tomo_labels['Number of motors'] > 0 else 0\n        })\n    solution_df = pd.DataFrame(solution_data)\n    submission_df = pd.DataFrame(predictions)\n\n    if not solution_df['tomo_id'].eq(submission_df['tomo_id']).all():\n        logger.error(f\"tomo_id mismatch: solution={solution_df['tomo_id'].tolist()}, submission={submission_df['tomo_id'].tolist()}\")\n        raise ValueError('Submitted tomo_id values do not match')\n\n    val_fbeta, val_TP, val_TN, val_FP, val_FN = calculate_fbeta_score(val_preds, val_trues, val_voxel_spacings)\n    logger.info(f\"Validation Fβ-score: {val_fbeta:.4f}\")\n    return val_loss / len(loader.dataset), val_fbeta, val_TP, val_TN, val_FP, val_FN\n\n\n# Training loop CONTROL AND CORRECT\nnum_epochs = 50 #Will change to 150\npatience = 50  # Will change to 50\ntrigger_times = 0\ntrain_losses = []\nval_losses = []\nval_fbetas = []\nbest_model_path = \"/kaggle/working/best_model.pth\"\ncheckpoint_path = \"/kaggle/working/checkpoint.pth\"\n\n# Run the pipeline\nstart_time = time.time()\nlogger.info(\"Starting training...\")\nmodel.train()\nfor epoch in range(start_epoch, num_epochs):\n    train_loss, train_fbeta, train_TP, train_TN, train_FP, train_FN, example_to_plot = train_epoch(\n        model, train_loader, criterion, optimizer, scaler, device\n    )\n    val_loss, val_fbeta, val_TP, val_TN, val_FP, val_FN = validate(model, val_loader, criterion, device)\n    logger.info(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.6f}, Train F2: {train_fbeta:.4f}, TP: {train_TP}, TN: {train_TN}, FP: {train_FP}, FN: {train_FN}\")\n    logger.info(f\"Val Loss: {val_loss:.6f}, Val F2: {val_fbeta:.4f}, TP: {val_TP}, TN: {val_TN}, FP: {val_FP}, FN: {val_FN}\")\n    logger.info(f\"GPU memory allocated after training: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    print(f\"Train Loss: {train_loss:.6f}, Train F2: {train_fbeta:.4f}, TP: {train_TP}, TN: {train_TN}, FP: {train_FP}, FN: {train_FN}\")\n    print(f\"Val Loss: {val_loss:.6f}, Val F2: {val_fbeta:.4f}, TP: {val_TP}, TN: {val_TN}, FP: {val_FP}, FN: {val_FN}\")\n\n    if example_to_plot is not None:\n        logger.info(f\"Plotting example for epoch {epoch+1}, Tomo ID: {example_to_plot['tomo_id']}\")\n        plot_slices(model, example_to_plot, device)\n        example_to_plot = None\n\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'scheduler_state_dict': scheduler.state_dict(),\n        'best_val_fbeta': best_val_fbeta,\n    }, checkpoint_path)\n\n    if val_fbeta > best_val_fbeta:\n        best_val_fbeta = val_fbeta\n        trigger_times = 0\n        torch.save(model.state_dict(), best_model_path)\n        logger.info(f\"Saved best model with Val F2: {best_val_fbeta:.4f}\")\n    else:\n        trigger_times += 1\n        logger.info(f\"No improvement in Val F2. Epochs without improvement: {trigger_times}/{patience}\")\n        if trigger_times >= patience:\n            logger.info(\"Early stopping triggered\")\n            model.load_state_dict(torch.load(best_model_path))\n            logger.info(f\"Loaded best model with Val F2: {best_val_fbeta:.4f}\")\n            break\n\n    gc.collect()\n    torch.cuda.empty_cache()\n\nif os.path.exists(best_model_path):\n    model.load_state_dict(torch.load(best_model_path))\n    logger.info(f\"Loaded best model with Val F2: {best_val_fbeta:.4f}\")\n\n# Use mentor's plot_test_predictions (unchanged)\ndef plot_test_predictions(submission_df, test_dataset):\n    valid_preds = submission_df[submission_df['Motor axis 0'] != -1]\n    shape_map = {item['tomo_id']: item['orig_shape'] for item in test_dataset.data}\n\n    for idx, row in valid_preds.iterrows():\n        tomo_id = row['tomo_id']\n        z = row['Motor axis 0']\n        y = row['Motor axis 1']\n        x = row['Motor axis 2']\n\n        slice_path = os.path.join('/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/test', tomo_id, f'slice_{z:04d}.jpg')\n        if not os.path.exists(slice_path):\n            logger.warning(f\"Slice {slice_path} not found, skipping.\")\n            continue\n\n        img = Image.open(slice_path).convert('L')\n        img_array = np.array(img)\n\n        orig_shape = shape_map[tomo_id]\n        orig_height, orig_width = orig_shape[0].item(), orig_shape[1].item()\n\n        plt.figure(figsize=(8, 8))\n        plt.imshow(img_array, cmap='gray')\n        plt.plot(x, y, 'ro', label='Predicted Motor', markersize=10)\n        plt.title(f\"Tomogram: {tomo_id}, Z: {z}, Shape: {int(orig_height)}x{int(orig_width)}\")\n        plt.legend()\n        plt.axis('off')\n        plt.show()\n\n    fig = plt.figure(figsize=(10, 8))\n    ax = fig.add_subplot(111, projection='3d')\n    \n    zs = valid_preds['Motor axis 0']\n    ys = valid_preds['Motor axis 1']\n    xs = valid_preds['Motor axis 2']\n\n    ax.scatter(xs, ys, zs, c='r', marker='o', label='Predicted Motors')\n    ax.set_xlabel('X (Motor axis 2)')\n    ax.set_ylabel('Y (Motor axis 1)')\n    ax.set_zlabel('Z (Motor axis 0)')\n    ax.set_title('3D Distribution of Predicted Motors in Test Set')\n    ax.legend()\n    plt.show()\n\n\n# Prediction on test set\ndef process_tomogram(tomo_id, model, test_dataset, device, index=0, total=1, confidence_threshold=0.8):\n    logger.info(f\"Processing tomogram {tomo_id} ({index}/{total})\") \n    tomo_dir = os.path.join('/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/test', tomo_id)\n    slice_files = sorted([os.path.join(tomo_dir, f) for f in os.listdir(tomo_dir) if f.endswith('.jpg')])\n    num_slices = len(slice_files)\n\n    tomo_data = next(item for item in test_dataset.data if item['tomo_id'] == tomo_id)\n    orig_shape = tomo_data['orig_shape']\n    max_z, max_y, max_x = orig_shape[0] - 1, orig_shape[1] - 1, orig_shape[2] - 1\n\n    all_detections = []\n    batch_size = 4 if device.startswith('cuda') else os.cpu_count() * 2\n\n    if device.startswith('cuda'):\n        gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n        free_mem = gpu_mem - torch.cuda.memory_allocated(0) / 1e9\n        # batch_size = max(4, min(16, int(free_mem / 2)))\n        batch_size = max(4, min(32, int(free_mem * 4)))  # Match competitor’s dynamic batching\n\n    model.eval()\n    with torch.no_grad():\n        for batch_start in range(0, num_slices, batch_size):\n            batch_end = min(batch_start + batch_size, num_slices)\n            batch_paths = slice_files[batch_start:batch_end]\n            batch_slices = preprocess_batch(batch_paths).to(device)\n\n            with amp.autocast('cuda'):  # Updated from torch.cuda.amp.autocast\n                pred_heatmaps, pred_sizes, pred_offsets = model(batch_slices)\n\n            for i, (heatmap, size, offset) in enumerate(zip(pred_heatmaps, pred_sizes, pred_offsets)):\n                confidence = heatmap.max().item()\n                if confidence >= confidence_threshold:\n                    pred_center_norm, pred_size_norm, _ = extract_centroid(heatmap, size, offset, threshold=confidence_threshold)\n                    z = batch_start + i\n                    pred_center, pred_size = denormalize_predictions(pred_center_norm, pred_size_norm, z, orig_shape[:2])\n                    x = max(0, min(max_x, pred_center[2].item()))  # Clamp to [0, max_x]\n                    y = max(0, min(max_y, pred_center[1].item()))  # Clamp to [0, max_y]\n                    z = max(0, min(max_z, z))  # Clamp to [0, max_z]\n                    all_detections.append({\n                        'z': z,\n                        'y': pred_center[1].item(),\n                        'x': pred_center[2].item(),\n                        'confidence': confidence,\n                        'width': pred_size[1].item(),\n                        'height': pred_size[0].item()\n                    })\n\n    print(f\"Processing tomogram {tomo_id}: Applying 3D NMS with distance_threshold=0.15\")  # Console output, increased threshold\n    logger.info(f\"Processing tomogram {tomo_id}: Applying 3D NMS with distance_threshold=0.15\")  # CHANGE in process_tomogram (line ~764): Added logging to track NMS application\n    final_detections = perform_3d_nms(all_detections, distance_threshold=0.15)  # CHANGE in process_tomogram (line ~766): Fixed TypeError by changing nms_threshold to distance_threshold\n    print(f\"Tomogram {tomo_id}: {len(final_detections)} detections after NMS\") \n    logger.info(f\"Tomogram {tomo_id}: {len(final_detections)} detections after NMS\")  # CHANGE in process_tomogram (line ~767): Added logging to report NMS results\n    if not final_detections:\n        print(f\"Tomogram {tomo_id}: No detections after NMS, returning default (-1, -1, -1)\") \n        logger.warning(f\"Tomogram {tomo_id}: No detections after NMS, returning default (-1, -1, -1)\")  # CHANGE in process_tomogram (line ~768): Added logging for default case\n        return {'tomo_id': tomo_id, 'Motor axis 0': -1, 'Motor axis 1': -1, 'Motor axis 2': -1}\n\n    final_detections.sort(key=lambda x: x['confidence'], reverse=True)\n    best_detection = final_detections[0]\n\n    return {\n        'tomo_id': tomo_id,\n        'Motor axis 0': round(best_detection['z']),  # CHANGE in process_tomogram (line ~773): Kept original author's rounding for consistency with submission format\n        'Motor axis 1': round(best_detection['y']),  # CHANGE in process_tomogram (line ~774): Kept original author's rounding for consistency with submission format\n        'Motor axis 2': round(best_detection['x'])   # CHANGE in process_tomogram (line ~775): Kept original author's rounding for consistency with submission format\n    }\n\ndef preprocess_batch(slice_paths, new_size=(256, 256)):\n    images = []\n    for path in slice_paths:\n        img = Image.open(path).convert('L')\n        img = T.functional.resize(img, new_size)\n        img = T.functional.to_tensor(img)\n        img = (img - img.mean()) / (img.std() + 1e-8)\n        images.append(img)\n    return torch.stack(images)\n\n# def perform_3d_nms(detections, distance_threshold=0.08): \n#     if not detections:\n#         return []\n#     detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)\n#     final_detections = []\n#     def distance_3d(d1, d2):\n#         return np.sqrt((d1['z'] - d2['z'])**2 + (d1['y'] - d2['y'])**2 + (d1['x'] - d2['x'])**2)\n#     trust_region = 4\n#     threshold = trust_region * distance_threshold\n#     while detections:\n#         best_detection = detections.pop(0)\n#         final_detections.append(best_detection)\n#         detections = [d for d in detections if distance_3d(d, best_detection) > threshold]\n#     return final_detections\n\ndef perform_3d_nms(detections, distance_threshold=0.1):  # Tightened threshold\n    if not detections:\n        return []\n    # Sort by confidence (highest first)\n    detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)\n    final_detections = []\n    # 3D distance function\n    def distance_3d(d1, d2):\n        return np.sqrt((d1['z'] - d2['z'])**2 + (d1['y'] - d2['y'])**2 + (d1['x'] - d2['x'])**2)    \n    # NMS loop\n    while detections:\n        best = detections.pop(0)\n        final_detections.append(best)\n        detections = [d for d in detections if distance_3d(d, best) > distance_threshold * 24]  # Box size=24    \n    return final_detections\n\n\ndef process_tomogram_wrapper(args):\n    try:\n        tomo_id, model, test_dataset, device, index, total = args\n        print(f\"Starting processing for tomogram {tomo_id} ({index}/{total})\")  # Console output\n        sys.stdout.flush()  # Force output\n        result = process_tomogram(tomo_id, model, test_dataset, device, index, total)\n        z = result.get('Motor axis 0', -1)\n        y = result.get('Motor axis 1', -1)\n        x = result.get('Motor axis 2', -1)\n        print(f\"Motor found in {tomo_id} at position: z={z}, y={y}, x={x}\")  # Console output\n        motors_found = 1 if z != -1 else 0\n        print(f\"Current detection rate: {index}/{index} ({100.0 * motors_found:.1f}%)\")  # Console output\n        sys.stdout.flush()\n        torch.cuda.empty_cache()\n        gc.collect()\n        return result  # Already a dict from process_tomogram\n    except Exception as e:\n        print(f\"Error processing tomogram {tomo_id}: {str(e)}\")  # Console output\n        sys.stdout.flush()\n        return {'tomo_id': tomo_id, 'Motor axis 0': -1, 'Motor axis 1': -1, 'Motor axis 2': -1}\n\n\ndef generate_submission(test_dataset, model, device):\n    print(\"Starting generate_submission\")\n    sys.stdout.flush()\n    logger.info(\"Starting generate_submission\")\n    total_tomos = len(test_dataset.tomo_ids)\n    model.to(device)\n    if device.startswith('cuda'):\n        try:\n            model.half()\n            logger.info(\"Using FP16 for inference\")\n            print(\"Using FP16 for inference\")\n        except:\n            logger.info(\"FP16 not supported\")\n            print(\"FP16 not supported\")\n    results = []\n    executor = None\n    try:\n        with ThreadPoolExecutor(max_workers=4) as executor:\n            args_list = [(tomo_id, model, test_dataset, device, i + 1, total_tomos) \n                         for i, tomo_id in enumerate(test_dataset.tomo_ids)]\n            results = list(executor.map(process_tomogram_wrapper, args_list))\n        logger.info(\"ThreadPoolExecutor completed and shut down\")\n        print(\"ThreadPoolExecutor completed and shut down\")\n    except Exception as e:\n        logger.error(f\"ThreadPoolExecutor failed: {str(e)}\", exc_info=True)\n        raise\n    finally:\n        if executor is not None:\n            executor._threads.clear()\n            logger.info(\"ThreadPoolExecutor threads cleared\")\n            print(\"ThreadPoolExecutor threads cleared\")  # Console output\n\n    submission_df = pd.DataFrame(results, columns=['tomo_id', 'Motor axis 0', 'Motor axis 1', 'Motor axis 2'])\n    try:\n        submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n        logger.info(\"Submission CSV saved successfully\")\n        print(\"Submission CSV saved successfully\")  # Console output\n    except Exception as e:\n        logger.error(f\"Failed to save submission CSV: {str(e)}\")\n        print(f\"Failed to save submission CSV: {str(e)}\")  # Console output\n        raise\n    motors_found = sum(1 for r in results if r['Motor axis 0'] != -1)  # Fix KeyError\n    print(f\"Submission complete! Motors detected: {motors_found}/{total_tomos} ({100.0 * motors_found / total_tomos:.1f}%)\")  # Console output\n    print(f\"Submission saved to: /kaggle/working/submission.csv\")  # Console output\n    print(f\"Submission preview:\\n{submission_df.to_string()}\")  # Console output\n    logger.info(f\"Submission saved. Motors detected: {motors_found}/{total_tomos}\")\n    print(f\"Submission saved. Motors detected: {motors_found}/{total_tomos}\")  # Console output\n    \n    torch.cuda.empty_cache()\n    gc.collect()\n    mem_mb = torch.cuda.memory_allocated() / 1024**2\n    logger.info(f\"GPU memory allocated after submission: {mem_mb:.2f} MB\")\n    print(f\"GPU memory allocated after submission: {mem_mb:.2f} MB\")  # Console output\n\n    torch.cuda.empty_cache()\n    gc.collect()\n    mem_mb = torch.cuda.memory_allocated() / 1024**2\n    print(f\"GPU memory allocated after submission: {mem_mb:.2f} MB\")  # Console output\n\n    # Backup submission.csv Because I am having an exception during the submission \n    try:\n        os.makedirs(\"/kaggle/working/output\", exist_ok=True)\n        if os.path.exists(\"/kaggle/working/submission.csv\"):\n            os.system(\"cp /kaggle/working/submission.csv /kaggle/working/output/submission.csv\")\n        logger.info(\"Submission CSV backed up for dataset creation\")\n        print(\"Submission CSV backed up for dataset creation\")  # Console output\n    except Exception as e:\n        logger.error(f\"Submission CSV backup failed: {str(e)}\")\n        print(f\"Submission CSV backup failed: {str(e)}\")  # Console output\n        \n    return submission_df\n\n\n# Main pipeline (replace your current pipeline)\ntry:\n    print(\"Generating test predictions...\")  # Console output\n    start_time = time.time()\n    submission_df = generate_submission(test_dataset, model, device)\n    \n    try:\n        os.makedirs(\"/kaggle/working/output\", exist_ok=True)\n        for file in [\"checkpoint.pth\", \"best_model.pth\", \"submission.csv\", \"training.log\"]:\n            if os.path.exists(f\"/kaggle/working/{file}\"):\n                os.system(f\"cp /kaggle/working/{file} /kaggle/working/output/{file}\")\n        print(\"Files backed up\")  # Console output\n    except Exception as e:\n        print(f\"File backup failed: {str(e)}\")  # Console output\n\n    print(\"Visualizing test predictions...\")  # Console output\n    try:\n        plot_test_predictions(submission_df, test_dataset)\n        print(\"Test predictions visualized\")  # Console output\n    except Exception as e:\n        print(f\"Visualization failed: {str(e)}\")  # Console output\n\n    total_time_sec = time.time() - start_time\n    total_time_min = total_time_sec / 60\n    print(f\"Total execution time: {total_time_sec:.2f} seconds ({total_time_min:.2f} minutes)\")  # Console output\n    print(\"Pipeline completed\")  # Console output\n\nexcept Exception as e:\n    print(f\"Pipeline failed: {str(e)}\")  # Console output\n    raise\n\nfinally:\n    sys.stdout.flush()\n    for handler in logger.handlers[:]:\n        handler.flush()\n        handler.close()\n        logger.removeHandler(handler)\n    print(\"Logger handlers released\")  # Console output\n    torch.cuda.empty_cache()\n    gc.collect()\n    mem_mb = torch.cuda.memory_allocated() / 1024**2\n    print(f\"GPU memory allocated at pipeline end: {mem_mb:.2f} MB\")  # Console output","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}